{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcd44fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nolan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nolan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import string\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kagglehub\n",
    "from pathlib import Path\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors # implements word vectors\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba9d21fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Running in local Python / VS Code\n",
      "Path to dataset files: C:\\Users\\Nolan\\.cache\\kagglehub\\datasets\\arhamrumi\\amazon-product-reviews\\versions\\1\n",
      "Dataset root: C:\\Users\\Nolan\\.cache\\kagglehub\\datasets\\arhamrumi\\amazon-product-reviews\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "# 1. Environment diagnostics\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"➡️ Running in Colab\")\n",
    "else:\n",
    "    print(\"➡️ Running in local Python / VS Code\")\n",
    "\n",
    "# 2. Downloading the dataset via kagglehub\n",
    "ds_path = kagglehub.dataset_download(\"arhamrumi/amazon-product-reviews\")\n",
    "path = Path(ds_path)\n",
    "\n",
    "print(\"Path to dataset files:\", ds_path)  \n",
    "\n",
    "print(\"Dataset root:\", ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "44bceeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'Reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed63f905",
   "metadata": {},
   "source": [
    "Набір даних містить такі ознаки для кожного відгуку:\n",
    "\n",
    "**Id** — ідентифікатор запису в наборі даних;  \n",
    "**ProductId** — унікальний ідентифікатор товару;  \n",
    "**UserId** — унікальний ідентифікатор користувача;  \n",
    "**ProfileName** — ім'я профілю користувача;  \n",
    "**HelpfulnessNumerato**r — кількість користувачів, які вважали огляд корисним;  \n",
    "**HelpfullnessDenominator** — кількість користувачів, які вказали, чи вважають вони відгук корисним чи ні;  \n",
    "**Score** — оцінка від 1 до 5;  \n",
    "**Time** — позначка часу перегляду відгуку;  \n",
    "**Summary** — короткий зміст відгуку;  \n",
    "**Text** — текст відгуку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "86158209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of uniq: Id                        568454\n",
      "ProductId                  74258\n",
      "UserId                    256059\n",
      "ProfileName               218415\n",
      "HelpfulnessNumerator         231\n",
      "HelpfulnessDenominator       234\n",
      "Score                          5\n",
      "Time                        3168\n",
      "Summary                   295742\n",
      "Text                      393579\n",
      "dtype: int64 \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568428 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Count of uniq: {df.nunique()}\", '\\n\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bff390cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: 42640 Remaining: 525814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(525814, 10)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before = df.shape[0]\n",
    "df = df.loc[df['Score'] != 3]\n",
    "after = df.shape[0]\n",
    "print(\"Removed:\", before - after, \"Remaining:\", after)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dd803628",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Створимо цільову змінну sentiment для розв’язання задачі бінарної класифікації. \n",
    "Наразі проігноруємо записи з нейтральним сентиментом, тобто ті, які мають рейтинг 3'''\n",
    "df['sentiment'] = [1 if score in [4, 5] else 0 for score in df['Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c07da6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fec8acc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(255)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aa874d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525554</th>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525555</th>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525556</th>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525557</th>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525558</th>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525559 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ProductId          UserId                      ProfileName  \\\n",
       "0       B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1       B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2       B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3       B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4       B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...            ...             ...                              ...   \n",
       "525554  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "525555  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "525556  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "525557  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "525558  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                          1                       1      5  1303862400   \n",
       "1                          0                       0      1  1346976000   \n",
       "2                          1                       1      4  1219017600   \n",
       "3                          3                       3      2  1307923200   \n",
       "4                          0                       0      5  1350777600   \n",
       "...                      ...                     ...    ...         ...   \n",
       "525554                     0                       0      5  1299628800   \n",
       "525555                     0                       0      2  1331251200   \n",
       "525556                     2                       2      5  1329782400   \n",
       "525557                     1                       1      5  1331596800   \n",
       "525558                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "525554                 Will not do without   \n",
       "525555                        disappointed   \n",
       "525556            Perfect for our maltipoo   \n",
       "525557  Favorite Training and reward treat   \n",
       "525558                         Great Honey   \n",
       "\n",
       "                                                     Text  sentiment  \n",
       "0       I have bought several of the Vitality canned d...          1  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...          0  \n",
       "2       This is a confection that has been around a fe...          1  \n",
       "3       If you are looking for the secret ingredient i...          0  \n",
       "4       Great taffy at a great price.  There was a wid...          1  \n",
       "...                                                   ...        ...  \n",
       "525554  Great for sesame chicken..this is a good if no...          1  \n",
       "525555  I'm disappointed with the flavor. The chocolat...          0  \n",
       "525556  These stars are small, so you can give 10-15 o...          1  \n",
       "525557  These are the BEST treats for training and rew...          1  \n",
       "525558  I am very satisfied ,product is as advertised,...          1  \n",
       "\n",
       "[525559 rows x 10 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a52ddfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserId</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A3TVZM3ZIXG8YW</th>\n",
       "      <th>1291420800</th>\n",
       "      <th>Filler food is empty, leaves your cat always needing more</th>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A29JUMRL1US6YP</th>\n",
       "      <th>1278201600</th>\n",
       "      <th>Fantastic Food for Good Cat Health</th>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3IE3TQ79W0YOR</th>\n",
       "      <th>1280793600</th>\n",
       "      <th>Please avoid!!</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A20P8VC55KPPCT</th>\n",
       "      <th>1310860800</th>\n",
       "      <th>Love all HappyBaby Tots!</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGPLJLVQ47QLT</th>\n",
       "      <th>1322870400</th>\n",
       "      <th>DOOMHAMMER approved</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZZV9PDNMCOZW</th>\n",
       "      <th>1329436800</th>\n",
       "      <th>Just what I needed</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZZVNIMTTMJH6</th>\n",
       "      <th>1268179200</th>\n",
       "      <th>pretty amazing</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZZY649VYAHQS</th>\n",
       "      <th>1309737600</th>\n",
       "      <th>I Have Spoken.</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZZYCJOJLUDYR</th>\n",
       "      <th>1337472000</th>\n",
       "      <th>Amazing flavor!!</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#oc-R109MU5OBBZ59U</th>\n",
       "      <th>1350086400</th>\n",
       "      <th>AWESOME Coffee!!!!</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363185 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  ProductId  \\\n",
       "UserId             Time       Summary                                                         \n",
       "A3TVZM3ZIXG8YW     1291420800 Filler food is empty, leaves your cat always ne...        199   \n",
       "A29JUMRL1US6YP     1278201600 Fantastic Food for Good Cat Health                        125   \n",
       "A3IE3TQ79W0YOR     1280793600 Please avoid!!                                             42   \n",
       "A20P8VC55KPPCT     1310860800 Love all HappyBaby Tots!                                   40   \n",
       "AGPLJLVQ47QLT      1322870400 DOOMHAMMER approved                                        36   \n",
       "...                                                                                     ...   \n",
       "AZZV9PDNMCOZW      1329436800 Just what I needed                                          1   \n",
       "AZZVNIMTTMJH6      1268179200 pretty amazing                                              1   \n",
       "AZZY649VYAHQS      1309737600 I Have Spoken.                                              1   \n",
       "AZZYCJOJLUDYR      1337472000 Amazing flavor!!                                            1   \n",
       "#oc-R109MU5OBBZ59U 1350086400 AWESOME Coffee!!!!                                          1   \n",
       "\n",
       "                                                                                  ProfileName  \\\n",
       "UserId             Time       Summary                                                           \n",
       "A3TVZM3ZIXG8YW     1291420800 Filler food is empty, leaves your cat always ne...          199   \n",
       "A29JUMRL1US6YP     1278201600 Fantastic Food for Good Cat Health                          125   \n",
       "A3IE3TQ79W0YOR     1280793600 Please avoid!!                                               42   \n",
       "A20P8VC55KPPCT     1310860800 Love all HappyBaby Tots!                                     40   \n",
       "AGPLJLVQ47QLT      1322870400 DOOMHAMMER approved                                          36   \n",
       "...                                                                                       ...   \n",
       "AZZV9PDNMCOZW      1329436800 Just what I needed                                            1   \n",
       "AZZVNIMTTMJH6      1268179200 pretty amazing                                                1   \n",
       "AZZY649VYAHQS      1309737600 I Have Spoken.                                                1   \n",
       "AZZYCJOJLUDYR      1337472000 Amazing flavor!!                                              1   \n",
       "#oc-R109MU5OBBZ59U 1350086400 AWESOME Coffee!!!!                                            1   \n",
       "\n",
       "                                                                                  HelpfulnessNumerator  \\\n",
       "UserId             Time       Summary                                                                    \n",
       "A3TVZM3ZIXG8YW     1291420800 Filler food is empty, leaves your cat always ne...                   199   \n",
       "A29JUMRL1US6YP     1278201600 Fantastic Food for Good Cat Health                                   125   \n",
       "A3IE3TQ79W0YOR     1280793600 Please avoid!!                                                        42   \n",
       "A20P8VC55KPPCT     1310860800 Love all HappyBaby Tots!                                              40   \n",
       "AGPLJLVQ47QLT      1322870400 DOOMHAMMER approved                                                   36   \n",
       "...                                                                                                ...   \n",
       "AZZV9PDNMCOZW      1329436800 Just what I needed                                                     1   \n",
       "AZZVNIMTTMJH6      1268179200 pretty amazing                                                         1   \n",
       "AZZY649VYAHQS      1309737600 I Have Spoken.                                                         1   \n",
       "AZZYCJOJLUDYR      1337472000 Amazing flavor!!                                                       1   \n",
       "#oc-R109MU5OBBZ59U 1350086400 AWESOME Coffee!!!!                                                     1   \n",
       "\n",
       "                                                                                  HelpfulnessDenominator  \\\n",
       "UserId             Time       Summary                                                                      \n",
       "A3TVZM3ZIXG8YW     1291420800 Filler food is empty, leaves your cat always ne...                     199   \n",
       "A29JUMRL1US6YP     1278201600 Fantastic Food for Good Cat Health                                     125   \n",
       "A3IE3TQ79W0YOR     1280793600 Please avoid!!                                                          42   \n",
       "A20P8VC55KPPCT     1310860800 Love all HappyBaby Tots!                                                40   \n",
       "AGPLJLVQ47QLT      1322870400 DOOMHAMMER approved                                                     36   \n",
       "...                                                                                                  ...   \n",
       "AZZV9PDNMCOZW      1329436800 Just what I needed                                                       1   \n",
       "AZZVNIMTTMJH6      1268179200 pretty amazing                                                           1   \n",
       "AZZY649VYAHQS      1309737600 I Have Spoken.                                                           1   \n",
       "AZZYCJOJLUDYR      1337472000 Amazing flavor!!                                                         1   \n",
       "#oc-R109MU5OBBZ59U 1350086400 AWESOME Coffee!!!!                                                       1   \n",
       "\n",
       "                                                                                  Score  \\\n",
       "UserId             Time       Summary                                                     \n",
       "A3TVZM3ZIXG8YW     1291420800 Filler food is empty, leaves your cat always ne...    199   \n",
       "A29JUMRL1US6YP     1278201600 Fantastic Food for Good Cat Health                    125   \n",
       "A3IE3TQ79W0YOR     1280793600 Please avoid!!                                         42   \n",
       "A20P8VC55KPPCT     1310860800 Love all HappyBaby Tots!                               40   \n",
       "AGPLJLVQ47QLT      1322870400 DOOMHAMMER approved                                    36   \n",
       "...                                                                                 ...   \n",
       "AZZV9PDNMCOZW      1329436800 Just what I needed                                      1   \n",
       "AZZVNIMTTMJH6      1268179200 pretty amazing                                          1   \n",
       "AZZY649VYAHQS      1309737600 I Have Spoken.                                          1   \n",
       "AZZYCJOJLUDYR      1337472000 Amazing flavor!!                                        1   \n",
       "#oc-R109MU5OBBZ59U 1350086400 AWESOME Coffee!!!!                                      1   \n",
       "\n",
       "                                                                                  Text  \\\n",
       "UserId             Time       Summary                                                    \n",
       "A3TVZM3ZIXG8YW     1291420800 Filler food is empty, leaves your cat always ne...   199   \n",
       "A29JUMRL1US6YP     1278201600 Fantastic Food for Good Cat Health                   125   \n",
       "A3IE3TQ79W0YOR     1280793600 Please avoid!!                                        42   \n",
       "A20P8VC55KPPCT     1310860800 Love all HappyBaby Tots!                              40   \n",
       "AGPLJLVQ47QLT      1322870400 DOOMHAMMER approved                                   36   \n",
       "...                                                                                ...   \n",
       "AZZV9PDNMCOZW      1329436800 Just what I needed                                     1   \n",
       "AZZVNIMTTMJH6      1268179200 pretty amazing                                         1   \n",
       "AZZY649VYAHQS      1309737600 I Have Spoken.                                         1   \n",
       "AZZYCJOJLUDYR      1337472000 Amazing flavor!!                                       1   \n",
       "#oc-R109MU5OBBZ59U 1350086400 AWESOME Coffee!!!!                                     1   \n",
       "\n",
       "                                                                                  sentiment  \n",
       "UserId             Time       Summary                                                        \n",
       "A3TVZM3ZIXG8YW     1291420800 Filler food is empty, leaves your cat always ne...        199  \n",
       "A29JUMRL1US6YP     1278201600 Fantastic Food for Good Cat Health                        125  \n",
       "A3IE3TQ79W0YOR     1280793600 Please avoid!!                                             42  \n",
       "A20P8VC55KPPCT     1310860800 Love all HappyBaby Tots!                                   40  \n",
       "AGPLJLVQ47QLT      1322870400 DOOMHAMMER approved                                        36  \n",
       "...                                                                                     ...  \n",
       "AZZV9PDNMCOZW      1329436800 Just what I needed                                          1  \n",
       "AZZVNIMTTMJH6      1268179200 pretty amazing                                              1  \n",
       "AZZY649VYAHQS      1309737600 I Have Spoken.                                              1  \n",
       "AZZYCJOJLUDYR      1337472000 Amazing flavor!!                                            1  \n",
       "#oc-R109MU5OBBZ59U 1350086400 AWESOME Coffee!!!!                                          1  \n",
       "\n",
       "[363185 rows x 7 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group_by_prod = df.groupby(['UserId', 'Time', 'Summary']).count().sort_values('ProductId', ascending=False)\n",
    "df_group_by_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5f754b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>B0002TJAZK</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>B0002TJAZK</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31782</th>\n",
       "      <td>B00106TG9Y</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52496</th>\n",
       "      <td>B003ANFMY8</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52501</th>\n",
       "      <td>B003ANFMY8</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499916</th>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499917</th>\n",
       "      <td>B009B87SAC</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514140</th>\n",
       "      <td>B003M5VM8O</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514690</th>\n",
       "      <td>B003MWGSKY</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532330</th>\n",
       "      <td>B000633ZFS</td>\n",
       "      <td>A3TVZM3ZIXG8YW</td>\n",
       "      <td>christopher hayes</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1291420800</td>\n",
       "      <td>Filler food is empty, leaves your cat always n...</td>\n",
       "      <td>This review will make me sound really stupid, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ProductId          UserId        ProfileName  HelpfulnessNumerator  \\\n",
       "2941    B0002TJAZK  A3TVZM3ZIXG8YW  christopher hayes                     7   \n",
       "2947    B0002TJAZK  A3TVZM3ZIXG8YW  christopher hayes                     0   \n",
       "31782   B00106TG9Y  A3TVZM3ZIXG8YW  christopher hayes                     2   \n",
       "52496   B003ANFMY8  A3TVZM3ZIXG8YW  christopher hayes                    19   \n",
       "52501   B003ANFMY8  A3TVZM3ZIXG8YW  christopher hayes                    18   \n",
       "...            ...             ...                ...                   ...   \n",
       "499916  B009B87SAC  A3TVZM3ZIXG8YW  christopher hayes                     6   \n",
       "499917  B009B87SAC  A3TVZM3ZIXG8YW  christopher hayes                     6   \n",
       "514140  B003M5VM8O  A3TVZM3ZIXG8YW  christopher hayes                     5   \n",
       "514690  B003MWGSKY  A3TVZM3ZIXG8YW  christopher hayes                     3   \n",
       "532330  B000633ZFS  A3TVZM3ZIXG8YW  christopher hayes                    11   \n",
       "\n",
       "        HelpfulnessDenominator  Score        Time  \\\n",
       "2941                        11      1  1291420800   \n",
       "2947                         2      1  1291420800   \n",
       "31782                        8      1  1291420800   \n",
       "52496                       21      1  1291420800   \n",
       "52501                       24      1  1291420800   \n",
       "...                        ...    ...         ...   \n",
       "499916                      14      1  1291420800   \n",
       "499917                      15      1  1291420800   \n",
       "514140                       9      1  1291420800   \n",
       "514690                       8      1  1291420800   \n",
       "532330                      16      1  1291420800   \n",
       "\n",
       "                                                  Summary  \\\n",
       "2941    Filler food is empty, leaves your cat always n...   \n",
       "2947    Filler food is empty, leaves your cat always n...   \n",
       "31782   Filler food is empty, leaves your cat always n...   \n",
       "52496   Filler food is empty, leaves your cat always n...   \n",
       "52501   Filler food is empty, leaves your cat always n...   \n",
       "...                                                   ...   \n",
       "499916  Filler food is empty, leaves your cat always n...   \n",
       "499917  Filler food is empty, leaves your cat always n...   \n",
       "514140  Filler food is empty, leaves your cat always n...   \n",
       "514690  Filler food is empty, leaves your cat always n...   \n",
       "532330  Filler food is empty, leaves your cat always n...   \n",
       "\n",
       "                                                     Text  sentiment  \n",
       "2941    This review will make me sound really stupid, ...          0  \n",
       "2947    This review will make me sound really stupid, ...          0  \n",
       "31782   This review will make me sound really stupid, ...          0  \n",
       "52496   This review will make me sound really stupid, ...          0  \n",
       "52501   This review will make me sound really stupid, ...          0  \n",
       "...                                                   ...        ...  \n",
       "499916  This review will make me sound really stupid, ...          0  \n",
       "499917  This review will make me sound really stupid, ...          0  \n",
       "514140  This review will make me sound really stupid, ...          0  \n",
       "514690  This review will make me sound really stupid, ...          0  \n",
       "532330  This review will make me sound really stupid, ...          0  \n",
       "\n",
       "[199 rows x 10 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_text = 'Filler food is empty, leaves your cat always needing more'\n",
    "duplicates_example = df.loc[\n",
    "    (df['UserId']=='A3TVZM3ZIXG8YW') &\n",
    "    (df['Time']==1291420800) &\n",
    "    (df['Summary']==search_text)\n",
    "]\n",
    "\n",
    "duplicates_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "133167ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364133, 10)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['UserId', 'Time', 'Text'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f405b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e212e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')).union({'also', 'would', 'much', 'many'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ea99c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "negations = {\n",
    "    'aren',\n",
    "    \"aren't\",\n",
    "    'couldn',\n",
    "    \"couldn't\",\n",
    "    'didn',\n",
    "    \"didn't\",\n",
    "    'doesn',\n",
    "    \"doesn't\",\n",
    "    'don',\n",
    "    \"don't\",\n",
    "    'hadn',\n",
    "    \"hadn't\",\n",
    "    'hasn',\n",
    "    \"hasn't\",\n",
    "    'haven',\n",
    "    \"haven't\",\n",
    "    'isn',\n",
    "    \"isn't\",\n",
    "    'mightn',\n",
    "    \"mightn't\",\n",
    "    'mustn',\n",
    "    \"mustn't\",\n",
    "    'needn',\n",
    "    \"needn't\",\n",
    "    'no',\n",
    "    'nor',\n",
    "    'not',\n",
    "    'shan',\n",
    "    \"shan't\",\n",
    "    'shouldn',\n",
    "    \"shouldn't\",\n",
    "    'wasn',\n",
    "    \"wasn't\",\n",
    "    'weren',\n",
    "    \"weren't\",\n",
    "    'won',\n",
    "    \"won't\",\n",
    "    'wouldn',\n",
    "    \"wouldn't\"\n",
    "}\n",
    "stop_words = stop_words.difference(negations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "03f6b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "118c0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable = ['parser','ner'])\n",
    "def normalize_text(raw_review):\n",
    "    \n",
    "    # Remove html tags\n",
    "    text = re.sub(\"<[^>]*>\", \" \", raw_review) # match <> and everything in between. [^>] - match everything except >\n",
    "    \n",
    "    # Remove emails\n",
    "    text = re.sub(\"\\\\S*@\\\\S*[\\\\s]+\", \" \", text) # match non-whitespace characters, @ and a whitespaces in the end\n",
    "    \n",
    "    # remove links\n",
    "    text = re.sub(\"https?:\\\\/\\\\/.*?[\\\\s]+\", \" \", text) # match http, s - zero or once, //, \n",
    "                                                    # any char 0-unlimited, whitespaces in the end\n",
    "        \n",
    "     # Convert to lower case, split into individual words\n",
    "    text = text.lower().split()\n",
    "    \n",
    "    # Replace contractions with their full versions\n",
    "    text = [contractions.get(word) if word in contractions else word \n",
    "            for word in text]\n",
    "   \n",
    "    # Re-splitting for the correct stop-words extraction\n",
    "    text = \" \".join(text).split()    \n",
    "    \n",
    "    # Remove stop words\n",
    "    text = [word for word in text if not word in stop_words]\n",
    "\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    # Remove non-letters        \n",
    "    text = re.sub(\"[^a-zA-Z' ]\", \"\", text) # match everything except letters and '\n",
    "\n",
    "    # Stem words. Need to define porter stemmer above\n",
    "    # text = [stemmer.stem(word) for word in text.split()]\n",
    "\n",
    "    # Lemmatize words. Need to define lemmatizer above\n",
    "    doc = nlp(text)\n",
    "    text = \" \".join([token.lemma_ for token in doc if len(token.lemma_) > 1 ])\n",
    "    \n",
    "    # Remove excesive whitespaces\n",
    "    text = re.sub(\"[\\\\s]+\", \" \", text)    \n",
    "    \n",
    "    # Join the words back into one string separated by space, and return the result.\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0a39a726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "On a quest for the perfedc1112t,,, !!!! <br />%%2%% popcorn to compliment the Whirley Pop.  \n",
      "Don\\'t get older, I\\'m beginning to appreciate the more \"natural\" popcorn varieties, and I suppose that\\'s\n",
      " what attracted me to the Arrowhead Mills Organic Yellow Popcorn.<br /> <br />I\\'m no \"organic\" food expert. \n",
      "   I just wanted some good tasting popcorn.  And, I feel like that\\'s what I got.  Using the Whirley Pop, with a very small amount of oil, I\\'ve had great results.\n",
      "##############################\n",
      "\n",
      "Normalized text:\n",
      "quest perfedct popcorn compliment whirley pop do not get old be begin appreciate natural popcorn variety suppose that be attract arrowhead mill organic yellow popcorn be no organic food expert want good tasting popcorn and feel like that be get use whirley pop small amount oil have great result\n"
     ]
    }
   ],
   "source": [
    "text = '''On a quest for the perfedc1112t,,, !!!! <br />%%2%% popcorn to compliment the Whirley Pop.  \n",
    "Don\\\\'t get older, I\\\\'m beginning to appreciate the more \"natural\" popcorn varieties, and I suppose that\\\\'s\n",
    " what attracted me to the Arrowhead Mills Organic Yellow Popcorn.<br /> <br />I\\\\'m no \"organic\" food expert. \n",
    "   I just wanted some good tasting popcorn.  And, I feel like that\\\\'s what I got.  Using the Whirley Pop, with a very small amount of oil, I\\\\'ve had great results.'''\n",
    "\n",
    "print(\"Original text:\\n\", text, \"\\n\", \"#\"*30, \"\\n\", sep=\"\")\n",
    "print(\"Normalized text:\\n\", normalize_text(text), sep=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ac52f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.groupby('sentiment').sample(2500, random_state=42)\n",
    "\n",
    "# df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e141753",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 364133/364133 [23:16<00:00, 260.72it/s]\n"
     ]
    }
   ],
   "source": [
    "df['text_normalized'] = df['Text'].progress_apply(normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9dbc7c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "      <td>buy several vitality can dog food product find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "      <td>product arrive label jumbo salt peanutsthe pea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1</td>\n",
       "      <td>confection around century light pillowy citrus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "      <td>look secret ingredient robitussin believe find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1</td>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ProductId          UserId                      ProfileName  \\\n",
       "0  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "   sentiment                                    text_normalized  \n",
       "0          1  buy several vitality can dog food product find...  \n",
       "1          0  product arrive label jumbo salt peanutsthe pea...  \n",
       "2          1  confection around century light pillowy citrus...  \n",
       "3          0  look secret ingredient robitussin believe find...  \n",
       "4          1  great taffy great price wide assortment yummy ...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "91a6a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = df.sample(frac=0.8, random_state=42).index\n",
    "test_idxs = [idx for idx in df.index if idx not in train_idxs]\n",
    "\n",
    "X_train = df.loc[train_idxs, 'text_normalized']\n",
    "y_train = df.loc[train_idxs, 'sentiment']\n",
    "\n",
    "X_test = df.loc[test_idxs, 'text_normalized']\n",
    "y_test = df.loc[test_idxs, 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ad389c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148264"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(X_train)\n",
    "\n",
    "len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5f2b9ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('input',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">input&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;content&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('encoding',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">encoding&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;utf-8&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('decode_error',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">decode_error&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;strict&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('strip_accents',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">strip_accents&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lowercase',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lowercase&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('preprocessor',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">preprocessor&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tokenizer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tokenizer&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('stop_words',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">stop_words&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('token_pattern',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">token_pattern&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;(?u)\\\\b\\\\w\\\\w+\\\\b&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ngram_range',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ngram_range&nbsp;</td>\n",
       "            <td class=\"value\">(1, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('analyzer',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">analyzer&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;word&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_df&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_df',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_df&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('vocabulary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">vocabulary&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('binary',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">binary&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dtype',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">dtype&nbsp;</td>\n",
       "            <td class=\"value\">&lt;class &#x27;numpy.int64&#x27;&gt;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9bd7646f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaa', 'aaaa', 'aaaaa', 'aaaaaa'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names_out()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ffb7e40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(291306, 148264)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 9609419 stored elements and shape (291306, 148264)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "print(X_train_vectorized.shape)\n",
    "X_train_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8d922b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nolan\\Documents\\My dokuments\\GoIT\\Deep_learning\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9403412285150121\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "proba = model.predict_proba(vect.transform(X_test))[:, 1]\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "41c2472a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wow', 145862),\n",
       " ('pleasantly', 98234),\n",
       " ('surprised', 126389),\n",
       " ('product', 101848),\n",
       " ('love', 74696),\n",
       " ('eat', 39745),\n",
       " ('dry', 38845),\n",
       " ('fruit', 50953),\n",
       " ('handy', 58028),\n",
       " ('pack', 93389),\n",
       " ('great', 55626),\n",
       " ('run', 110448),\n",
       " ('treat', 134494),\n",
       " ('buying', 17480),\n",
       " ('lunchboxe', 75322),\n",
       " ('asian', 6918),\n",
       " ('pear', 95392),\n",
       " ('daughter', 32542),\n",
       " ('favorite', 45648),\n",
       " ('please', 98247)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vect.vocabulary_.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d0e3d",
   "metadata": {},
   "source": [
    "Для подальшого швидкого тестування різних варіантів обробки даних напишемо допоміжну функцію."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02c4bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(text_column, algorithm, ngrams=(1,1)):\n",
    "    \n",
    "    X_train = df.loc[train_idxs, text_column]\n",
    "    X_test = df.loc[test_idxs, text_column]\n",
    "\n",
    "    y_train = df.loc[train_idxs, 'sentiment']\n",
    "    y_test = df.loc[test_idxs, 'sentiment']\n",
    "    \n",
    "    if algorithm == 'cv':\n",
    "        vect = CountVectorizer(ngram_range=ngrams).fit(X_train)\n",
    "    elif algorithm == 'tfidf':\n",
    "        vect = TfidfVectorizer(ngram_range=ngrams).fit(X_train)\n",
    "    else:\n",
    "        raise ValueError('Select correct algorithm: `cv` or `tfidf`')\n",
    "            \n",
    "    print('Vocabulary length: ', len(vect.vocabulary_))\n",
    "    \n",
    "    # transform the documents in the training data to a document-term matrix\n",
    "\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    print('Document-term matrix shape:', X_train_vectorized.shape)\n",
    "    \n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_train_vectorized, y_train)\n",
    "    \n",
    "    predictions = model.predict_proba(vect.transform(X_test))[:, 1]\n",
    "\n",
    "    print('AUC: ', roc_auc_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e8c2e967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length:  148264\n",
      "Document-term matrix shape: (291306, 148264)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nolan\\Documents\\My dokuments\\GoIT\\Deep_learning\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9403412285150121\n"
     ]
    }
   ],
   "source": [
    "get_preds('text_normalized', 'cv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e31dbc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length:  148264\n",
      "Document-term matrix shape: (291306, 148264)\n",
      "AUC:  0.9542780328549247\n"
     ]
    }
   ],
   "source": [
    "get_preds('text_normalized', 'tfidf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aa60ba7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length:  2999090\n",
      "Document-term matrix shape: (291306, 2999090)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nolan\\Documents\\My dokuments\\GoIT\\Deep_learning\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.9631257324144284\n"
     ]
    }
   ],
   "source": [
    "get_preds('text_normalized', 'cv', (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4dbc2ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length:  2999090\n",
      "Document-term matrix shape: (291306, 2999090)\n",
      "AUC:  0.9672269189863768\n"
     ]
    }
   ],
   "source": [
    "get_preds('text_normalized', 'tfidf', (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "30b85167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(data):\n",
    "  corpus = []\n",
    "  for sentence in data:\n",
    "    word_list = sentence.split(\" \")\n",
    "    corpus.append(word_list)\n",
    "  return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "911706c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buy',\n",
       " 'several',\n",
       " 'vitality',\n",
       " 'can',\n",
       " 'dog',\n",
       " 'food',\n",
       " 'product',\n",
       " 'find',\n",
       " 'good',\n",
       " 'quality',\n",
       " 'product',\n",
       " 'look',\n",
       " 'like',\n",
       " 'stew',\n",
       " 'process',\n",
       " 'meat',\n",
       " 'smell',\n",
       " 'well',\n",
       " 'labrador',\n",
       " 'finicky',\n",
       " 'appreciate',\n",
       " 'product',\n",
       " 'well',\n",
       " 'most']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = build_corpus(df['text_normalized'])\n",
    "corpus[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5421f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb_from_scratch = word2vec.Word2Vec(corpus, vector_size=100, window=5, min_count=50, workers=4)\n",
    "\n",
    "# saving vectors\n",
    "model_emb_from_scratch.wv.save_word2vec_format('model_emb_from_scratch.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "54f7d2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вектори успішно завантажено!\n"
     ]
    }
   ],
   "source": [
    "# Завантажуємо вектори з файлу\n",
    "my_vectors = KeyedVectors.load_word2vec_format('model_emb_from_scratch.bin', binary=True)\n",
    "\n",
    "print(\"Вектори успішно завантажено!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a4c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Слова, схожі на 'expensive':\n",
      "[('costly', 0.8722464442253113), ('pricey', 0.8475409746170044), ('cheap', 0.789085865020752), ('pricy', 0.7803586721420288), ('overpriced', 0.7537978887557983), ('pricier', 0.7172571420669556), ('cost', 0.711898922920227), ('spendy', 0.6908905506134033), ('cheaper', 0.6570128798484802), ('overprice', 0.6349856853485107)]\n"
     ]
    }
   ],
   "source": [
    "# Спробуй щось специфічне для Amazon, наприклад 'expensive' (дорогий)\n",
    "print(\"\\nСлова, схожі на 'expensive':\")\n",
    "try:\n",
    "    print(my_vectors.most_similar('expensive'))\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f05f06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding: \n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = {}\n",
    "        \n",
    "    def convert(self, source, ipnut_file_path, output_file_path):\n",
    "        '''\n",
    "        Converts word embeddings from GloVe format to Word2Vec format\n",
    "        '''\n",
    "        if source == 'glove':\n",
    "            input_file = datapath(ipnut_file_path)\n",
    "            output_file = get_tmpfile(output_file_path)\n",
    "            glove2word2vec(input_file, output_file)\n",
    "        elif source in ['word2vec', 'fasttext', 'from_scratch']:\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext, or from_scratch')\n",
    "        \n",
    "    def load(self, source, file_path):\n",
    "        '''\n",
    "        Loads a specified word embedding model from a file\n",
    "        '''\n",
    "        print(datetime.datetime.now(), 'start: loading', source)\n",
    "        if source in ['glove', 'fasttext']:\n",
    "            self.model[source] = gensim.models.KeyedVectors.load_word2vec_format(file_path)\n",
    "        elif source in ['word2vec', 'from_scratch']:\n",
    "            self.model[source] = gensim.models.KeyedVectors.load_word2vec_format(file_path, binary=True)\n",
    "        else:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext, or from_scratch')\n",
    "            \n",
    "        print(datetime.datetime.now(), 'end: loading', source)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def get_model(self, source):\n",
    "        '''\n",
    "        Retrieves the loaded word embedding model\n",
    "        '''\n",
    "        if source not in ['glove', 'word2vec', 'fasttext', 'from_scratch']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext, or from_scratch')\n",
    "            \n",
    "        return self.model[source]\n",
    "    \n",
    "    def get_words(self, source, size=None):\n",
    "        '''\n",
    "        Retrieves a list of words from the model\n",
    "        '''\n",
    "        if source not in ['glove', 'word2vec', 'fasttext', 'from_scratch']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext, or from_scratch')\n",
    "\n",
    "        if size is None:\n",
    "            return [w for w in self.get_model(source=source).key_to_index]\n",
    "        else:\n",
    "            results = []\n",
    "            for i, word in enumerate(self.get_model(source=source).key_to_index):\n",
    "                if i >= size:\n",
    "                    break\n",
    "                results.append(word)\n",
    "            return results\n",
    "        \n",
    "        return Exception('Unexpected flow')\n",
    "    \n",
    "    def get_dimension(self, source):\n",
    "        '''\n",
    "        Retrieves the dimension of word vectors in the model\n",
    "        '''\n",
    "        if source not in ['glove', 'word2vec', 'fasttext', 'from_scratch']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext, or from_scratch')\n",
    "        \n",
    "        return self.get_model(source=source).vectors[0].shape[0]\n",
    "    \n",
    "    def get_vectors(self, source, words=None):\n",
    "        '''\n",
    "        Retrieves vectors for specified words or for all words in the model\n",
    "        '''\n",
    "        if source not in ['glove', 'word2vec', 'fasttext', 'from_scratch']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext, or from_scratch')\n",
    "        \n",
    "        if words is None:\n",
    "            words = self.get_words(source=source)\n",
    "            \n",
    "        embedding = np.empty((len(words), self.get_dimension(source=source)), dtype=np.float32)\n",
    "        for i, word in enumerate(words):\n",
    "            embedding[i] = self.get_vector(source=source, word=word)\n",
    "                \n",
    "        return embedding\n",
    "        \n",
    "    \n",
    "    def get_vector(self, source, word):\n",
    "        '''\n",
    "        Retrieves the vector representation of a single word\n",
    "        '''\n",
    "        if source not in ['glove', 'word2vec', 'fasttext', 'from_scratch']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext, or from_scratch')\n",
    "            \n",
    "        if source not in self.model:\n",
    "            raise ValueError('Did not load %s model yet' % source)\n",
    "        \n",
    "        try:\n",
    "            return self.model[source][word]\n",
    "        except KeyError as e:\n",
    "            dims = self.model[source][0].shape\n",
    "            vect = np.empty(dims)\n",
    "            vect[:] = np.nan\n",
    "            return vect\n",
    "            \n",
    "    def get_synonym(self, source, word, topn=5):\n",
    "        '''\n",
    "        Retrieves synonyms for a given word\n",
    "        '''\n",
    "        if source not in ['glove', 'word2vec', 'fasttext', 'from_scratch']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext, or from_scratch')\n",
    "            \n",
    "        if source not in self.model:\n",
    "            raise ValueError('Did not load %s model yet' % source)\n",
    "        \n",
    "        try:\n",
    "            return self.model[source].most_similar(positive=word, topn=topn)\n",
    "        except KeyError as e:\n",
    "            raise\n",
    "    \n",
    "    def get_distance_between_two_words(self, source, word1, word2):\n",
    "        '''\n",
    "        Calculates cosine similarity between two words in the model\n",
    "        '''\n",
    "        if source not in ['glove', 'word2vec', 'fasttext', 'from_scratch']:\n",
    "            raise ValueError('Possible value of source are glove, word2vec, fasttext, or from_scratch')\n",
    "            \n",
    "        if source not in self.model:\n",
    "            raise ValueError('Did not load %s model yet' % source)\n",
    "        \n",
    "        try:\n",
    "            return self.model[source].similarity(word1, word2)\n",
    "        except KeyError as e:\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "71619d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding = WordEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "42b0b821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-18 15:12:03.216887 start: loading from_scratch\n",
      "2025-12-18 15:12:03.248410 end: loading from_scratch\n"
     ]
    }
   ],
   "source": [
    "# word2vec_file_path = 'pretrained_models/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "# fasttext_file_path = 'pretrained_models/wiki-news-300d-1M.vec'\n",
    "\n",
    "from_scratch_file_path = 'model_emb_from_scratch.bin'\n",
    "\n",
    "# adding absolute path for correct gensim work\n",
    "# downloaded_glove_file_path = os.path.abspath('pretrained_models') + '/glove.6B.50d.txt'\n",
    "# glove_file_path = os.path.abspath('pretrained_models') + '/glove.6B.50d.vec'\n",
    "\n",
    "try:\n",
    "    word_embedding.load(source='from_scratch', file_path=from_scratch_file_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Помилка: Файл {from_scratch_file_path} не знайдено. Перевір шлях!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_embedding.convert(source='glove', ipnut_file_path=downloaded_glove_file_path, output_file_path=glove_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bad8ecb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: from_scratch\n",
      "[ 2.6831627   1.3476357  -1.4496872   0.93928796 -1.9091156  -1.6276546\n",
      "  2.7061791   3.6508634   0.0967804   0.00791635  1.7608486   1.6253062\n",
      " -1.8491086   0.11836294  2.5336206   0.7067682  -0.7633619   0.24489829\n",
      " -1.330402    0.24993835  0.3750465  -1.1859053   1.8556513   1.2459805\n",
      "  2.756841   -1.7531066  -3.2526398  -5.1765423  -0.14817668 -0.18143839\n",
      " -0.7891922  -1.7849101  -1.4421382  -2.0194638  -4.299649    4.4633813\n",
      "  1.4478363   2.3502495   2.810452    1.0866938  -1.2085488   0.03623242\n",
      "  0.09146767  1.6445264   1.233292    0.20943132 -4.1044407   1.2211795\n",
      " -0.38373768 -1.8678396   0.90110326  1.8209499  -1.8441017  -1.1734719\n",
      "  1.2036536   2.4842527  -1.2873391  -3.553294    1.8199185  -1.587625\n",
      "  0.8172394  -0.5806897  -1.3481711   0.5547119   2.7400177   0.58666843\n",
      "  0.30444112 -3.7092197  -2.0056803  -0.5600727  -2.9299028  -0.6160517\n",
      " -4.175562   -0.38197666  3.2718177  -0.12175719 -1.941347    0.2476754\n",
      " -0.10531218  0.993097    0.00878957 -2.1932125   0.5915786  -1.6263682\n",
      "  0.94443065  3.5808218   0.66622865 -2.056088    4.3480973  -2.7902226\n",
      "  1.4235753   0.07561442  2.9209769  -0.05583036 -2.1357229   1.22952\n",
      "  1.6706024  -2.2432663  -0.5955731   0.09353106]\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "for source in ['from_scratch']: # 'word2vec', 'fasttext',\n",
    "    print('Source: %s' % (source))\n",
    "    print(word_embedding.get_vector(source=source, word='cat'))\n",
    "    print(len(word_embedding.get_vector(source=source, word='cat')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d4a7783b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: from_scratch\n",
      "[('kitty', 0.9006395936012268), ('kitten', 0.8226063251495361), ('dog', 0.8149734735488892), ('feline', 0.7507354617118835), ('friskie', 0.7498754262924194)]\n"
     ]
    }
   ],
   "source": [
    "for source in ['from_scratch']: # 'word2vec', 'fasttext',\n",
    "    print('Source: %s' % (source))\n",
    "    print(word_embedding.get_synonym(source=source, word='cat', topn=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4837f689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: from_scratch\n",
      "0.90063965\n"
     ]
    }
   ],
   "source": [
    "w1 = 'cat'\n",
    "w2 = 'kitty'\n",
    "\n",
    "for source in ['from_scratch']: # 'word2vec', 'fasttext'\n",
    "    print('Source: %s' % (source))\n",
    "    print(word_embedding.get_distance_between_two_words(source=source,word1=w1, word2=w2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "969fa309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok2vec(tokens, source:str, avg:str):\n",
    "    vects = word_embedding.get_vectors(source=source, words=tokens)\n",
    "\n",
    "    if avg == 'mean':\n",
    "        return np.nanmean(vects, axis=0)\n",
    "    elif avg == 'sum':\n",
    "        return np.nansum(vects, axis=0)\n",
    "    else:\n",
    "        raise ValueError('Select correct averaging method: sum or mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "33a53b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-18 15:42:03.671760 start: loading from_scratch\n",
      "2025-12-18 15:42:03.706980 end: loading from_scratch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.WordEmbedding at 0x20e3d0dbe10>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding = WordEmbedding()\n",
    "\n",
    "source = 'from_scratch'\n",
    "\n",
    "word_embedding.load(source=source, file_path=from_scratch_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a625afdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Nolan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "C:\\Users\\Nolan\\AppData\\Local\\Temp\\ipykernel_58976\\549319055.py:5: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(vects, axis=0)\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "train_idxs = df.sample(frac=0.8, random_state=42).index\n",
    "test_idxs = [idx for idx in df.index if idx not in train_idxs]\n",
    "\n",
    "X_train = df.loc[train_idxs, 'text_normalized'].apply(\n",
    "    word_tokenize).apply(lambda x: tok2vec(x, source, 'mean')).to_numpy()\n",
    "\n",
    "X_test = df.loc[test_idxs, 'text_normalized'].apply(\n",
    "    word_tokenize).apply(lambda x: tok2vec(x, source, 'mean')).to_numpy()\n",
    "\n",
    "X_train = np.stack(X_train, axis=0)\n",
    "X_test = np.stack(X_test, axis=0)\n",
    "\n",
    "y_train = df.loc[train_idxs, 'sentiment']\n",
    "y_test = df.loc[test_idxs, 'sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "af1831c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Починаю навчання...\n",
      "AUC Score: 0.9306697421302594\n"
     ]
    }
   ],
   "source": [
    "# 1. Чистимо дані від пустот\n",
    "X_train = np.nan_to_num(X_train)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "\n",
    "# 2. Створюємо модель\n",
    "model = LogisticRegression(random_state=42, max_iter=1000) # max_iter іноді треба збільшити\n",
    "\n",
    "# 3. Вчимо\n",
    "print(\"Починаю навчання...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Прогнозуємо\n",
    "predictions = model.predict(X_test)\n",
    "# Якщо хочеш точнішу метрику ROC AUC, краще брати ймовірності (predict_proba), а не класи\n",
    "probs = model.predict_proba(X_test)[:, 1] \n",
    "\n",
    "print('AUC Score:', roc_auc_score(y_test, probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e64394b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenized = df['text_normalized'].apply(word_tokenize).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ace818c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['look', 'secret', 'ingredient', 'robitussin', 'believe', 'find', 'it', 'get', 'addition', 'root', 'beer', 'extract', 'order', 'which', 'good', 'make', 'cherry', 'soda', 'flavor', 'medicinal'], tags=[3])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tagged_document(list_of_list_of_words):\n",
    "    for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "        yield gensim.models.doc2vec.TaggedDocument(list_of_words, [i])\n",
    "        \n",
    "text_tokenized_tagget = list(tagged_document(text_tokenized))\n",
    "\n",
    "text_tokenized_tagget[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "47ba25d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Doc2Vec = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=5, epochs=200)\n",
    "\n",
    "model_Doc2Vec.build_vocab(text_tokenized_tagget)\n",
    "\n",
    "model_Doc2Vec.train(text_tokenized_tagget, total_examples=model_Doc2Vec.corpus_count, epochs=model_Doc2Vec.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "81989fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Розміри X_train: (291306, 300)\n",
      "Розміри X_test: (72827, 300)\n"
     ]
    }
   ],
   "source": [
    "# 1. Отримуємо вектори (це ти вже зробив, але на всяк випадок)\n",
    "X = [model_Doc2Vec.infer_vector(x) for x in text_tokenized]\n",
    "\n",
    "# 2. !!! МАГІЯ ТУТ !!!\n",
    "# Перетворюємо список X на Pandas Series і кажемо: \n",
    "# \"Використовуй ті ж самі номери-індекси, що були в оригінальному DataFrame\"\n",
    "X_series = pd.Series(X, index=df.index)\n",
    "\n",
    "# 3. Тепер розбиваємо, використовуючи .loc (який шукає по Імені індекса, а не по порядку)\n",
    "X_train = X_series.loc[train_idxs].tolist()\n",
    "X_test = X_series.loc[test_idxs].tolist()\n",
    "\n",
    "# 4. Перетворюємо на масиви Numpy для моделі\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "print(\"Розміри X_train:\", X_train.shape)\n",
    "print(\"Розміри X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6ccfcd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7517709698927251\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print('AUC: ', roc_auc_score(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
