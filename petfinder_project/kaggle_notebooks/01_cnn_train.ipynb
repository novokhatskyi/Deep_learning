{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed98ba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nolan\\Documents\\My dokuments\\GoIT\\Deep_learning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5132eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train exists: True\n",
      "test exists : True\n",
      "images dir  : True\n",
      "folds exists: True\n"
     ]
    }
   ],
   "source": [
    "IS_KAGGLE = False\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    COMP_PATH = Path(\"../input/deep-learning-for-computer-vision-and-nlp-2026-01\")\n",
    "    FOLDS_PATH = Path(\"../input/petfinder-train-folds/train_folds.csv\")  # зміниться під твою назву на Kaggle\n",
    "else:\n",
    "    COMP_PATH = Path(\"../data/raw\")\n",
    "    FOLDS_PATH = Path(\"../data/artifacts/train_folds.csv\")\n",
    "\n",
    "TRAIN_CSV = COMP_PATH / \"train.csv\"\n",
    "TEST_CSV  = COMP_PATH / \"test.csv\"\n",
    "IMG_DIR_TRAIN   = COMP_PATH / \"images/images/train\"\n",
    "IMG_DIR_TEST    = COMP_PATH / \"images/images/test\"\n",
    "IMG_DIR = COMP_PATH / \"images/images\"\n",
    "\n",
    "print(\"train exists:\", TRAIN_CSV.exists())\n",
    "print(\"test exists :\", TEST_CSV.exists())\n",
    "print(\"images dir  :\", IMG_DIR.exists())\n",
    "print(\"folds exists:\", FOLDS_PATH.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f59bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6431, 3) (1891, 2) (6431, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>Description</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d3b4f29f8</td>\n",
       "      <td>Mayleen and Flo are two lovely adorable sister...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e9dc82251</td>\n",
       "      <td>A total of 5 beautiful Tabbys available for ad...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8111f6d4a</td>\n",
       "      <td>Two-and-a-half month old girl. Very manja and ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693a90fda</td>\n",
       "      <td>Neil is a healthy and active ~2-month-old fema...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9d08c85ef</td>\n",
       "      <td>Gray kitten available for adoption in sungai p...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID                                        Description  AdoptionSpeed\n",
       "0  d3b4f29f8  Mayleen and Flo are two lovely adorable sister...              2\n",
       "1  e9dc82251  A total of 5 beautiful Tabbys available for ad...              2\n",
       "2  8111f6d4a  Two-and-a-half month old girl. Very manja and ...              2\n",
       "3  693a90fda  Neil is a healthy and active ~2-month-old fema...              2\n",
       "4  9d08c85ef  Gray kitten available for adoption in sungai p...              2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_df  = pd.read_csv(TEST_CSV)\n",
    "folds_df = pd.read_csv(FOLDS_PATH)\n",
    "\n",
    "print(train_df.shape, test_df.shape, folds_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814a6039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after merge: (6431, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d3b4f29f8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e9dc82251</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8111f6d4a</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693a90fda</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9d08c85ef</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  AdoptionSpeed  fold\n",
       "0  d3b4f29f8              2     3\n",
       "1  e9dc82251              2     3\n",
       "2  8111f6d4a              2     2\n",
       "3  693a90fda              2     4\n",
       "4  9d08c85ef              2     3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.merge(folds_df, on=[\"PetID\", \"AdoptionSpeed\"], how=\"inner\")\n",
    "print(\"after merge:\", train_df.shape)\n",
    "train_df[[\"PetID\",\"AdoptionSpeed\",\"fold\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6645804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total image files: 28472\n",
      "sample: ['000a290e4-1.jpg', '000a290e4-2.jpg', '000fb9572-1.jpg', '000fb9572-2.jpg', '000fb9572-3.jpg', '000fb9572-4.jpg', '000fb9572-5.jpg', '000fb9572-6.jpg', '001b1507c-1.jpg', '001b1507c-2.jpg']\n"
     ]
    }
   ],
   "source": [
    "train_imgs = list(IMG_DIR_TRAIN.glob(\"*\"))\n",
    "print(\"total image files:\", len(train_imgs))\n",
    "print(\"sample:\", [p.name for p in train_imgs[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6dc100e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match rate: 1.0\n",
      "Example prefixes: ['7196383a7', '37fadf608', '97a80f8b3', '43c661026', '32ac38a9f', '6b240dd0b', '9e1caf559', '85ca390a0', '1a5e5d34c', 'eb6bb82fd']\n"
     ]
    }
   ],
   "source": [
    "# Check matching between image files and CSV PetIDs\n",
    "\n",
    "petids_in_csv = set(train_df[\"PetID\"].astype(str))\n",
    "\n",
    "sample_files = random.sample(train_imgs, 200)\n",
    "prefixes = [p.name.split(\"-\", 1)[0] for p in sample_files]\n",
    "\n",
    "match_rate = sum(pref in petids_in_csv for pref in prefixes) / len(prefixes)\n",
    "\n",
    "print(\"Match rate:\", match_rate)\n",
    "print(\"Example prefixes:\", prefixes[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35230b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PetIDs with images: 6431\n"
     ]
    }
   ],
   "source": [
    "petid_to_images = defaultdict(list)\n",
    "\n",
    "for img_path in train_imgs:\n",
    "    pet_id = img_path.name.split(\"-\", 1)[0]\n",
    "    petid_to_images[pet_id].append(img_path)\n",
    "\n",
    "print(\"Total PetIDs with images:\", len(petid_to_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6c081f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total image files: 9448\n",
      "sample: ['0008c5398-1.jpg', '0008c5398-2.jpg', '0008c5398-3.jpg', '0008c5398-4.jpg', '0008c5398-5.jpg', '0008c5398-6.jpg', '004c2f355-1.jpg', '004c2f355-2.jpg', '00553ae55-1.jpg', '00553ae55-2.jpg']\n"
     ]
    }
   ],
   "source": [
    "test_imgs = list(IMG_DIR_TEST.glob(\"*\"))\n",
    "print(\"total image files:\", len(test_imgs))\n",
    "print(\"sample:\", [p.name for p in test_imgs[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c06dc5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match rate: 0.99\n",
      "Example prefixes: ['d8fc9bc28', '61be9a64f', '7d52177d6', 'd320b7121', 'c7b3c09d4', '982dce813', 'bbfc5274f', '29466dcf4', '1d5a59ca9', 'a0909c2bb']\n"
     ]
    }
   ],
   "source": [
    "# Check matching between image files and CSV PetIDs\n",
    "\n",
    "petids_in_csv = set(test_df[\"PetID\"].astype(str))\n",
    "\n",
    "sample_files = random.sample(test_imgs, 200)\n",
    "prefixes = [p.name.split(\"-\", 1)[0] for p in sample_files]\n",
    "\n",
    "match_rate = sum(pref in petids_in_csv for pref in prefixes) / len(prefixes)\n",
    "\n",
    "print(\"Match rate:\", match_rate)\n",
    "print(\"Example prefixes:\", prefixes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34d30177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total PetIDs with images: 1899\n",
      "Total PetIDs with images: 6431\n"
     ]
    }
   ],
   "source": [
    "petid_to_images_test = defaultdict(list)\n",
    "\n",
    "for img_path in test_imgs:\n",
    "    pet_id = img_path.name.split(\"-\", 1)[0]\n",
    "    petid_to_images_test[pet_id].append(img_path)\n",
    "\n",
    "print(\"Total PetIDs with images:\", len(petid_to_images_test))\n",
    "print(\"Total PetIDs with images:\", len(petid_to_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06c0fe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered test_df: 1891 -> 1887\n"
     ]
    }
   ],
   "source": [
    "available_test_petids = set(petid_to_images_test.keys())\n",
    "\n",
    "before = len(test_df)\n",
    "test_df = test_df[test_df[\"PetID\"].isin(available_test_petids)].reset_index(drop=True)\n",
    "after = len(test_df)\n",
    "\n",
    "print(f\"Filtered test_df: {before} -> {after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ae4e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002230dea\n",
      "[WindowsPath('../data/raw/images/images/train/002230dea-1.jpg'), WindowsPath('../data/raw/images/images/train/002230dea-2.jpg'), WindowsPath('../data/raw/images/images/train/002230dea-3.jpg'), WindowsPath('../data/raw/images/images/train/002230dea-4.jpg')]\n"
     ]
    }
   ],
   "source": [
    "# example output\n",
    "some_pet = list(petid_to_images.keys())[3]\n",
    "print(some_pet)\n",
    "print(petid_to_images[some_pet])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8636dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self, df, petid_to_images, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.petid_to_images = petid_to_images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        pet_id = row[\"PetID\"]\n",
    "        label = row[\"AdoptionSpeed\"] - 1  # make labels 0-based\n",
    "\n",
    "        img_path = random.choice(self.petid_to_images[pet_id])  # baseline: randomly choose one image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows, n_cols = 4, 3\n",
    "n = n_rows * n_cols\n",
    "\n",
    "sample_paths = random.sample(train_imgs, k=n)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, p in zip(axes, sample_paths):\n",
    "    img = Image.open(p).convert(\"RGB\")\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(p.name, fontsize=9)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c857afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "weights = EfficientNet_B0_Weights.DEFAULT\n",
    "mean = weights.transforms().mean\n",
    "std  = weights.transforms().std\n",
    "\n",
    "train_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=mean, std=std),\n",
    "])\n",
    "\n",
    "val_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=mean, std=std),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4dac8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5144, 1287)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLD = 0\n",
    "\n",
    "df_tr = train_df[train_df[\"fold\"] != FOLD].reset_index(drop=True)\n",
    "df_va = train_df[train_df[\"fold\"] == FOLD].reset_index(drop=True)\n",
    "\n",
    "train_ds = PetDataset(df_tr, petid_to_images, transform=train_tfms)\n",
    "val_ds   = PetDataset(df_va, petid_to_images, transform=val_tfms)\n",
    "\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c48fee14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train batches: 160\n",
      "val batches  : 41\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0  \n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=False,     \n",
    "    drop_last=True       \n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(\"train batches:\", len(train_loader))\n",
    "print(\"val batches  :\", len(val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c877f09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdcec303",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 4\n",
    "\n",
    "def build_model(num_classes=NUM_CLASSES):\n",
    "    weights = EfficientNet_B0_Weights.DEFAULT\n",
    "    model = efficientnet_b0(weights=weights)\n",
    "\n",
    "    in_features = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15c61909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\Nolan/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20.5M/20.5M [01:04<00:00, 334kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dropout(p=0.2, inplace=True)\n",
      "  (1): Linear(in_features=1280, out_features=4, bias=True)\n",
      ")\n",
      "Output shape: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Створюємо модель\n",
    "model = build_model()\n",
    "\n",
    "# Перевіряємо архітектуру\n",
    "print(model.classifier) \n",
    "# Має вивести щось типу:\n",
    "# Sequential(\n",
    "#   (0): Dropout(p=0.2, inplace=True)\n",
    "#   (1): Linear(in_features=1280, out_features=4, bias=True)  <-- ТУТ МАЄ БУТИ 4!\n",
    "# )\n",
    "\n",
    "# Перевіряємо на фейкових даних\n",
    "dummy_input = torch.randn(2, 3, 224, 224) # 2 картинки, 3 канали, 224x224\n",
    "output = model(dummy_input)\n",
    "print(\"Output shape:\", output.shape) \n",
    "# Має бути: torch.Size([2, 4]) -> (2 картинки, 4 класи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76819cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()  # режим навчання (вмикає dropout, batchnorm у train-режимі)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"train\", leave=False)\n",
    "\n",
    "    for x, y in pbar:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()          # обнуляємо градієнти\n",
    "        logits = model(x)              # прямий прохід\n",
    "        loss = criterion(logits, y)    # рахуємо loss\n",
    "\n",
    "        loss.backward()                # зворотний прохід (градієнти)\n",
    "        optimizer.step()               # крок оптимізатора\n",
    "\n",
    "        bs = x.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        total += bs\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "\n",
    "        pbar.set_postfix(loss=float(loss.item()))\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_epoch_with_probs(model, loader, criterion, device):\n",
    "    model.eval()  # режим оцінки (вимикає dropout тощо)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    probs_list = []\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"valid\", leave=False)\n",
    "\n",
    "    for x, y in pbar:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        bs = x.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        total += bs\n",
    "\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "\n",
    "        probs = F.softmax(logits, dim=1).detach().cpu().numpy()  # (bs, 4)\n",
    "        probs_list.append(probs)\n",
    "\n",
    "        pbar.set_postfix(loss=float(loss.item()))\n",
    "\n",
    "    val_loss = running_loss / total\n",
    "    val_acc = correct / total\n",
    "    val_probs = np.vstack(probs_list)  # (N_val, 4)\n",
    "\n",
    "    return val_loss, val_acc, val_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09ceeb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing train petids: 0\n",
      "missing test  petids: 0\n"
     ]
    }
   ],
   "source": [
    "missing_train = sum(pid not in petid_to_images for pid in train_df[\"PetID\"].values)\n",
    "missing_test  = sum(pid not in petid_to_images_test for pid in test_df[\"PetID\"].values)\n",
    "\n",
    "print(\"missing train petids:\", missing_train)\n",
    "print(\"missing test  petids:\", missing_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d354a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "EPOCHS = 3\n",
    "LR = 1e-3\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2     \n",
    "PIN_MEMORY = True\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# OOF probabilities для кожного рядка train_df (N, 4)\n",
    "oof_probs = np.zeros((len(train_df), NUM_CLASSES), dtype=np.float32)\n",
    "\n",
    "\n",
    "# 5-FOLD LOOP\n",
    "\n",
    "for fold in range(N_SPLITS):\n",
    "    print(f\"\\n===== FOLD {fold} / {N_SPLITS - 1} =====\")\n",
    "\n",
    "    df_tr = train_df[train_df[\"fold\"] != fold].reset_index(drop=True)\n",
    "    df_va = train_df[train_df[\"fold\"] == fold].reset_index(drop=True)\n",
    "\n",
    "    train_ds = PetDataset(df_tr, petid_to_images, transform=train_tfms)\n",
    "    val_ds   = PetDataset(df_va, petid_to_images, transform=val_tfms)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    model = build_model(NUM_CLASSES).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    # ---- train epochs ----\n",
    "    for epoch in range(EPOCHS):\n",
    "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        va_loss, va_acc, _ = valid_epoch_with_probs(model, val_loader, criterion, device)\n",
    "        print(f\"epoch {epoch+1}/{EPOCHS} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | val loss {va_loss:.4f} acc {va_acc:.4f}\")\n",
    "\n",
    "    # ---- final val probs (OOF) ----\n",
    "    va_loss, va_acc, fold_probs = valid_epoch_with_probs(model, val_loader, criterion, device)\n",
    "    print(f\"FOLD {fold} FINAL | val loss {va_loss:.4f} acc {va_acc:.4f}\")\n",
    "\n",
    "    # запис у правильні рядки train_df\n",
    "    val_index = train_df.index[train_df[\"fold\"] == fold].to_numpy()\n",
    "    oof_probs[val_index] = fold_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b17ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_out = pd.DataFrame({\n",
    "    \"PetID\": train_df[\"PetID\"].values,\n",
    "    \"fold\": train_df[\"fold\"].values,\n",
    "})\n",
    "for c in range(NUM_CLASSES):\n",
    "    oof_out[f\"pred_{c}\"] = oof_probs[:, c]\n",
    "\n",
    "oof_out.to_csv(\"cnn_oof.csv\", index=False)\n",
    "print(\"Saved cnn_oof.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_TEST = True   # якщо False — блок тесту просто не виконується\n",
    "\n",
    "class PetTestDataset(Dataset):\n",
    "    def __init__(self, df, petid_to_images_test, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.petid_to_images = petid_to_images_test\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        pet_id = row[\"PetID\"]\n",
    "\n",
    "        img_path = random.choice(self.petid_to_images[pet_id])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, pet_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e11c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_test_probs(model, loader, device):\n",
    "    model.eval()\n",
    "    probs_list = []\n",
    "    petids = []\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"test\", leave=False)\n",
    "    for x, pid in pbar:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        probs = F.softmax(logits, dim=1).detach().cpu().numpy()\n",
    "\n",
    "        probs_list.append(probs)\n",
    "        petids.extend(list(pid))\n",
    "\n",
    "    return np.array(petids), np.vstack(probs_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c0186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_TEST:\n",
    "    test_probs_accum = np.zeros((len(test_df), NUM_CLASSES), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a7e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ---- TEST PROBS ----\n",
    "if DO_TEST:\n",
    "    test_ds = PetTestDataset(test_df, petid_to_images_test, transform=val_tfms)\n",
    "    test_loader = DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=PIN_MEMORY,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    _, fold_test_probs = predict_test_probs(model, test_loader, device)\n",
    "    test_probs_accum += fold_test_probs / N_SPLITS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_TEST:\n",
    "    test_out = pd.DataFrame({\"PetID\": test_df[\"PetID\"].values})\n",
    "    for c in range(NUM_CLASSES):\n",
    "        test_out[f\"pred_{c}\"] = test_probs_accum[:, c]\n",
    "\n",
    "    test_out.to_csv(\"cnn_test.csv\", index=False)\n",
    "    print(\"Saved cnn_test.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
