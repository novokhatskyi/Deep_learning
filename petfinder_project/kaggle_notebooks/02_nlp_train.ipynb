{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:12:39.678389Z",
     "iopub.status.busy": "2026-01-24T18:12:39.678179Z",
     "iopub.status.idle": "2026-01-24T18:12:43.672276Z",
     "shell.execute_reply": "2026-01-24T18:12:43.671349Z",
     "shell.execute_reply.started": "2026-01-24T18:12:39.678368Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.0)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (26.0rc2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-24T18:12:43.674201Z",
     "iopub.status.busy": "2026-01-24T18:12:43.673949Z",
     "iopub.status.idle": "2026-01-24T18:12:58.651742Z",
     "shell.execute_reply": "2026-01-24T18:12:58.651166Z",
     "shell.execute_reply.started": "2026-01-24T18:12:43.674170Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, random, gc\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup, AutoConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:12:58.653039Z",
     "iopub.status.busy": "2026-01-24T18:12:58.652539Z",
     "iopub.status.idle": "2026-01-24T18:12:58.662592Z",
     "shell.execute_reply": "2026-01-24T18:12:58.662010Z",
     "shell.execute_reply.started": "2026-01-24T18:12:58.653011Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train exists: True\n",
      "test exists : True\n",
      "folds exists: True\n"
     ]
    }
   ],
   "source": [
    "COMP_PATH = Path(\"/kaggle/input/deep-learning-for-computer-vision-and-nlp-2026-01\")\n",
    "FOLDS_PATH = Path(\"/kaggle/input/petfinder-train-folds/train_folds.csv\") \n",
    "\n",
    "train_csv = COMP_PATH / \"train.csv\"\n",
    "test_csv = COMP_PATH / \"test.csv\"\n",
    "\n",
    "print(\"train exists:\", train_csv.exists())\n",
    "print(\"test exists :\", test_csv.exists())\n",
    "print(\"folds exists:\", FOLDS_PATH.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:12:58.663904Z",
     "iopub.status.busy": "2026-01-24T18:12:58.663560Z",
     "iopub.status.idle": "2026-01-24T18:12:58.778980Z",
     "shell.execute_reply": "2026-01-24T18:12:58.778210Z",
     "shell.execute_reply.started": "2026-01-24T18:12:58.663874Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6431, 3)\n",
      "Test shape : (1891, 2)\n",
      "Folds shape: (6431, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_csv)\n",
    "test_df  = pd.read_csv(test_csv)\n",
    "folds_df = pd.read_csv(FOLDS_PATH)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape :\", test_df.shape)\n",
    "print(\"Folds shape:\", folds_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:12:58.781038Z",
     "iopub.status.busy": "2026-01-24T18:12:58.780720Z",
     "iopub.status.idle": "2026-01-24T18:12:58.802734Z",
     "shell.execute_reply": "2026-01-24T18:12:58.802002Z",
     "shell.execute_reply.started": "2026-01-24T18:12:58.781017Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6431 entries, 0 to 6430\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   PetID          6431 non-null   object\n",
      " 1   Description    6426 non-null   object\n",
      " 2   AdoptionSpeed  6431 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 150.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:12:58.804052Z",
     "iopub.status.busy": "2026-01-24T18:12:58.803735Z",
     "iopub.status.idle": "2026-01-24T18:12:58.811484Z",
     "shell.execute_reply": "2026-01-24T18:12:58.810716Z",
     "shell.execute_reply.started": "2026-01-24T18:12:58.804022Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1891 entries, 0 to 1890\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   PetID        1891 non-null   object\n",
      " 1   Description  1890 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 29.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:12:58.812861Z",
     "iopub.status.busy": "2026-01-24T18:12:58.812492Z",
     "iopub.status.idle": "2026-01-24T18:12:58.826979Z",
     "shell.execute_reply": "2026-01-24T18:12:58.826259Z",
     "shell.execute_reply.started": "2026-01-24T18:12:58.812813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df[\"Description\"] = train_df[\"Description\"].fillna(\"\")\n",
    "test_df[\"Description\"] = test_df[\"Description\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:12:58.828110Z",
     "iopub.status.busy": "2026-01-24T18:12:58.827823Z",
     "iopub.status.idle": "2026-01-24T18:12:58.841124Z",
     "shell.execute_reply": "2026-01-24T18:12:58.840531Z",
     "shell.execute_reply.started": "2026-01-24T18:12:58.828084Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdoptionSpeed\n",
      "1    1197\n",
      "2    1773\n",
      "3    1328\n",
      "4    2133\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"AdoptionSpeed\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:12:58.842170Z",
     "iopub.status.busy": "2026-01-24T18:12:58.841833Z",
     "iopub.status.idle": "2026-01-24T18:12:58.859222Z",
     "shell.execute_reply": "2026-01-24T18:12:58.858410Z",
     "shell.execute_reply.started": "2026-01-24T18:12:58.842142Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset:\n",
      "       PetID                                        Description  AdoptionSpeed\n",
      "0  d3b4f29f8  Mayleen and Flo are two lovely adorable sister...              2\n",
      "1  e9dc82251  A total of 5 beautiful Tabbys available for ad...              2\n",
      "2  8111f6d4a  Two-and-a-half month old girl. Very manja and ...              2\n",
      "3  693a90fda  Neil is a healthy and active ~2-month-old fema...              2\n",
      "4  9d08c85ef  Gray kitten available for adoption in sungai p...              2 \n",
      "\n",
      "test dataset:\n",
      "       PetID                                        Description\n",
      "0  6697a7f62  This cute little puppy is looking for a loving...\n",
      "1  23b64fe21  These 3 puppies was rescued from a mechanic sh...\n",
      "2  41e824cbe  Ara needs a forever home! Believe me, he's a r...\n",
      "3  6c3d7237b  i rescue this homeless dog 2 years ago but my ...\n",
      "4  97b0b5d92  We found him at a shopping mall at a very clea... \n",
      "\n",
      "folds dataset:\n",
      "       PetID  AdoptionSpeed  fold\n",
      "0  d3b4f29f8              2     3\n",
      "1  e9dc82251              2     3\n",
      "2  8111f6d4a              2     2\n",
      "3  693a90fda              2     4\n",
      "4  9d08c85ef              2     3\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset:\")\n",
    "print(train_df.head(), \"\\n\")\n",
    "print(\"test dataset:\")\n",
    "print(test_df.head(), \"\\n\")\n",
    "print(\"folds dataset:\")\n",
    "print(folds_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:12:58.860521Z",
     "iopub.status.busy": "2026-01-24T18:12:58.860230Z",
     "iopub.status.idle": "2026-01-24T18:12:58.918861Z",
     "shell.execute_reply": "2026-01-24T18:12:58.917727Z",
     "shell.execute_reply.started": "2026-01-24T18:12:58.860493Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:12:58.920598Z",
     "iopub.status.busy": "2026-01-24T18:12:58.920037Z",
     "iopub.status.idle": "2026-01-24T18:13:24.354537Z",
     "shell.execute_reply": "2026-01-24T18:13:24.353684Z",
     "shell.execute_reply.started": "2026-01-24T18:12:58.920569Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e334c250b4470b944df42aea12d635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769278382.170015      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769278382.228060      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769278382.690905      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769278382.690946      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769278382.690948      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769278382.690950      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c772aabee3924467afc7fc185ba033e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf55f7baf7645e3b29139243644dd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6313fc731949c39676c7b0cf3349c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d0a854c152461293ccbc5d74f68267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"bert-base-cased\"\n",
    "num_classes = 4\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:24.356139Z",
     "iopub.status.busy": "2026-01-24T18:13:24.355560Z",
     "iopub.status.idle": "2026-01-24T18:13:24.365127Z",
     "shell.execute_reply": "2026-01-24T18:13:24.364535Z",
     "shell.execute_reply.started": "2026-01-24T18:13:24.356116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Mayleen and Flo are two lovely adorable sisters. They are very friendly and affectionate, but wary of strangers and make good watchdogs. Mayleen has golden hues on her face, making her a husky look - alike. Flo has a darker face with brown feet, and is the more outgoing and dominat of the two. Looking for good homes. Adopters must vaccinate and spay them. [SEP]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train_df.loc[0, \"Description\"]  \n",
    "inputs = tokenizer(text)\n",
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:24.366164Z",
     "iopub.status.busy": "2026-01-24T18:13:24.365907Z",
     "iopub.status.idle": "2026-01-24T18:13:24.410294Z",
     "shell.execute_reply": "2026-01-24T18:13:24.409421Z",
     "shell.execute_reply.started": "2026-01-24T18:13:24.366132Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Mayleen and Flo are two lovely adorable sisters. They are very friendly and affectionate, but wary of strangers and make good watchdogs. Mayleen has golden hues on her face, making her a husky look - alike. Flo has a darker face with brown feet, and is the more outgoing and dominat of the two. Looking for good homes. Adopters must vaccinate and spay them. [SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer( \n",
    "    text, \n",
    "    max_length=200, \n",
    "    truncation=True,\n",
    "    return_overflowing_tokens=True, \n",
    ") \n",
    "  \n",
    "for ids in inputs[\"input_ids\"]: \n",
    "    print(tokenizer.decode(ids)); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:24.413246Z",
     "iopub.status.busy": "2026-01-24T18:13:24.412964Z",
     "iopub.status.idle": "2026-01-24T18:13:24.424702Z",
     "shell.execute_reply": "2026-01-24T18:13:24.424092Z",
     "shell.execute_reply.started": "2026-01-24T18:13:24.413225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView({'input_ids': [[101, 1318, 21180, 1105, 143, 2858, 1132, 1160, 9020, 27627, 5919, 119, 1220, 1132, 1304, 4931, 1105, 12721, 2193, 117, 1133, 16970, 1104, 15712, 1105, 1294, 1363, 2824, 14082, 1116, 119, 1318, 21180, 1144, 5404, 177, 10589, 1113, 1123, 1339, 117, 1543, 1123, 170, 24418, 1440, 118, 11609, 119, 143, 2858, 1144, 170, 9934, 1339, 1114, 3058, 1623, 117, 1105, 1110, 1103, 1167, 25194, 1105, 1202, 14503, 1204, 1104, 1103, 1160, 119, 8540, 1111, 1363, 4481, 119, 24930, 4184, 5759, 1538, 191, 7409, 16430, 2193, 1105, 22620, 1183, 1172, 119, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'offset_mapping': [[(0, 0), (0, 3), (3, 7), (8, 11), (12, 13), (13, 15), (16, 19), (20, 23), (24, 30), (31, 39), (40, 47), (47, 48), (49, 53), (54, 57), (58, 62), (63, 71), (72, 75), (76, 85), (85, 88), (88, 89), (90, 93), (94, 98), (99, 101), (102, 111), (112, 115), (116, 120), (121, 125), (126, 131), (131, 134), (134, 135), (135, 136), (137, 140), (140, 144), (145, 148), (149, 155), (156, 157), (157, 160), (161, 163), (164, 167), (168, 172), (172, 173), (174, 180), (181, 184), (185, 186), (187, 192), (193, 197), (197, 198), (198, 203), (203, 204), (205, 206), (206, 208), (209, 212), (213, 214), (215, 221), (222, 226), (227, 231), (232, 237), (238, 242), (242, 243), (244, 247), (248, 250), (251, 254), (255, 259), (260, 268), (269, 272), (273, 275), (275, 279), (279, 280), (281, 283), (284, 287), (288, 291), (291, 292), (293, 300), (301, 304), (305, 309), (310, 315), (315, 316), (317, 319), (319, 321), (321, 325), (326, 330), (331, 332), (332, 334), (334, 337), (337, 340), (341, 344), (345, 348), (348, 349), (350, 354), (354, 355), (0, 0)]], 'overflow_to_sample_mapping': [0]})\n",
      "num chunks: 1\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer( \n",
    "    text, \n",
    "    max_length=200, \n",
    "    truncation=True, \n",
    "    return_overflowing_tokens=True, \n",
    "    return_offsets_mapping=True, \n",
    " ) \n",
    "inputs.keys()\n",
    "print(inputs.keys())\n",
    "print(\"num chunks:\", len(inputs[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:24.425893Z",
     "iopub.status.busy": "2026-01-24T18:13:24.425609Z",
     "iopub.status.idle": "2026-01-24T18:13:26.023541Z",
     "shell.execute_reply": "2026-01-24T18:13:26.022910Z",
     "shell.execute_reply.started": "2026-01-24T18:13:24.425867Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 6431\n",
      "min  : 2\n",
      "p50  : 66\n",
      "p90  : 199\n",
      "p95  : 287\n",
      "p99  : 557\n",
      "max  : 1487\n"
     ]
    }
   ],
   "source": [
    "lengths = train_df[\"Description\"].fillna(\"\").astype(str).apply(\n",
    "    lambda x: len(tokenizer(x, add_special_tokens=True, truncation=False)[\"input_ids\"])\n",
    ")\n",
    "\n",
    "print(\"count:\", lengths.shape[0])\n",
    "print(\"min  :\", lengths.min())\n",
    "print(\"p50  :\", int(lengths.quantile(0.50)))\n",
    "print(\"p90  :\", int(lengths.quantile(0.90)))\n",
    "print(\"p95  :\", int(lengths.quantile(0.95)))\n",
    "print(\"p99  :\", int(lengths.quantile(0.99)))\n",
    "print(\"max  :\", lengths.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:26.024745Z",
     "iopub.status.busy": "2026-01-24T18:13:26.024467Z",
     "iopub.status.idle": "2026-01-24T18:13:26.030591Z",
     "shell.execute_reply": "2026-01-24T18:13:26.030034Z",
     "shell.execute_reply.started": "2026-01-24T18:13:26.024710Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, max_length=287):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "       \n",
    "        item = {key: val.squeeze(0) for key, val in inputs.items()}\n",
    "       \n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "       \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:26.031832Z",
     "iopub.status.busy": "2026-01-24T18:13:26.031562Z",
     "iopub.status.idle": "2026-01-24T18:13:26.043421Z",
     "shell.execute_reply": "2026-01-24T18:13:26.042767Z",
     "shell.execute_reply.started": "2026-01-24T18:13:26.031804Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_length = 288\n",
    "n_folds = 5\n",
    "num_workers = 0 \n",
    "epochs = 4\n",
    "lr = 2e-5\n",
    "weight_decay=0.01\n",
    "pin_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:26.044965Z",
     "iopub.status.busy": "2026-01-24T18:13:26.044244Z",
     "iopub.status.idle": "2026-01-24T18:13:26.065677Z",
     "shell.execute_reply": "2026-01-24T18:13:26.064994Z",
     "shell.execute_reply.started": "2026-01-24T18:13:26.044944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (6431, 4)\n",
      "missing fold: 0\n"
     ]
    }
   ],
   "source": [
    "master_df = train_df.merge(\n",
    "    folds_df[[\"PetID\", \"fold\"]],\n",
    "    on=\"PetID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "print(\"shape:\", master_df.shape)\n",
    "print(\"missing fold:\", master_df[\"fold\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:26.066768Z",
     "iopub.status.busy": "2026-01-24T18:13:26.066508Z",
     "iopub.status.idle": "2026-01-24T18:13:26.072824Z",
     "shell.execute_reply": "2026-01-24T18:13:26.072171Z",
     "shell.execute_reply.started": "2026-01-24T18:13:26.066747Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "0 3\n"
     ]
    }
   ],
   "source": [
    "master_df[\"label\"] = master_df[\"AdoptionSpeed\"] - 1  # Convert to 0-3\n",
    "print(master_df[\"AdoptionSpeed\"].min(), master_df[\"AdoptionSpeed\"].max())\n",
    "print(master_df[\"label\"].min(), master_df[\"label\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:26.073916Z",
     "iopub.status.busy": "2026-01-24T18:13:26.073646Z",
     "iopub.status.idle": "2026-01-24T18:13:26.095459Z",
     "shell.execute_reply": "2026-01-24T18:13:26.094876Z",
     "shell.execute_reply.started": "2026-01-24T18:13:26.073888Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "№ Fold: 0\n",
      "Train batches: 322\n",
      " Val batches: 81 \n",
      "\n",
      "№ Fold: 1\n",
      "Train batches: 322\n",
      " Val batches: 81 \n",
      "\n",
      "№ Fold: 2\n",
      "Train batches: 322\n",
      " Val batches: 81 \n",
      "\n",
      "№ Fold: 3\n",
      "Train batches: 322\n",
      " Val batches: 81 \n",
      "\n",
      "№ Fold: 4\n",
      "Train batches: 322\n",
      " Val batches: 81 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in range(n_folds):\n",
    "    print(\"№ Fold:\", fold)\n",
    "\n",
    "    train = master_df[master_df[\"fold\"] != fold]\n",
    "    val = master_df[master_df[\"fold\"] == fold]\n",
    "\n",
    "    train_texts = train[\"Description\"].values\n",
    "    train_labels = train[\"label\"].values\n",
    "\n",
    "    val_texts = val[\"Description\"].values\n",
    "    val_labels = val[\"label\"].values\n",
    "\n",
    "    train_dataset = PetFinderDataset(\n",
    "        texts=train_texts,\n",
    "        labels=train_labels,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    val_dataset = PetFinderDataset(\n",
    "        texts=val_texts,\n",
    "        labels=val_labels,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "\n",
    "    print(\"Train batches:\", len(train_loader))\n",
    "    print(\" Val batches:\", len(val_loader), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:26.096661Z",
     "iopub.status.busy": "2026-01-24T18:13:26.096359Z",
     "iopub.status.idle": "2026-01-24T18:13:26.122739Z",
     "shell.execute_reply": "2026-01-24T18:13:26.122046Z",
     "shell.execute_reply.started": "2026-01-24T18:13:26.096639Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([16, 288]) torch.int64\n",
      "token_type_ids torch.Size([16, 288]) torch.int64\n",
      "attention_mask torch.Size([16, 288]) torch.int64\n",
      "labels torch.Size([16]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:26.123964Z",
     "iopub.status.busy": "2026-01-24T18:13:26.123707Z",
     "iopub.status.idle": "2026-01-24T18:13:26.140796Z",
     "shell.execute_reply": "2026-01-24T18:13:26.140275Z",
     "shell.execute_reply.started": "2026-01-24T18:13:26.123944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels min/max: 0 3\n",
      "unique (first 50): tensor([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"labels min/max:\", batch[\"labels\"].min().item(), batch[\"labels\"].max().item())\n",
    "print(\"unique (first 50):\", torch.unique(batch[\"labels\"])[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:26.141876Z",
     "iopub.status.busy": "2026-01-24T18:13:26.141590Z",
     "iopub.status.idle": "2026-01-24T18:13:27.290124Z",
     "shell.execute_reply": "2026-01-24T18:13:27.289332Z",
     "shell.execute_reply.started": "2026-01-24T18:13:26.141829Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step loss: 1.3669534921646118\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "outputs = model(\n",
    "    input_ids=batch[\"input_ids\"].to(device),\n",
    "    attention_mask=batch[\"attention_mask\"].to(device),\n",
    "    labels=batch[\"labels\"].to(device),\n",
    ")\n",
    "loss = outputs.loss\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"train step loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:27.291492Z",
     "iopub.status.busy": "2026-01-24T18:13:27.291195Z",
     "iopub.status.idle": "2026-01-24T18:13:27.607523Z",
     "shell.execute_reply": "2026-01-24T18:13:27.606749Z",
     "shell.execute_reply.started": "2026-01-24T18:13:27.291464Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.2724, device='cuda:0')\n",
      "logits shape: torch.Size([16, 4])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=batch[\"input_ids\"].to(device),\n",
    "        attention_mask=batch[\"attention_mask\"].to(device),\n",
    "        labels=batch[\"labels\"].to(device),\n",
    "    )\n",
    "\n",
    "print(\"loss:\", outputs.loss)\n",
    "print(\"logits shape:\", outputs.logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:27.609042Z",
     "iopub.status.busy": "2026-01-24T18:13:27.608618Z",
     "iopub.status.idle": "2026-01-24T18:13:27.614373Z",
     "shell.execute_reply": "2026-01-24T18:13:27.613742Z",
     "shell.execute_reply.started": "2026-01-24T18:13:27.609010Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, device, scheduler=None):\n",
    "    pbar = tqdm(train_loader, desc=\"Training\")\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in pbar:\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"].to(device),\n",
    "            attention_mask=batch[\"attention_mask\"].to(device),\n",
    "            labels=batch[\"labels\"].to(device),\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        avg_so_far = total_loss / (pbar.n + 1)\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", avg=f\"{avg_so_far:.4f}\")\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:27.615934Z",
     "iopub.status.busy": "2026-01-24T18:13:27.615482Z",
     "iopub.status.idle": "2026-01-24T18:13:27.627522Z",
     "shell.execute_reply": "2026-01-24T18:13:27.626893Z",
     "shell.execute_reply.started": "2026-01-24T18:13:27.615913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_one_epoch(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    pbar = tqdm(val_loader, desc=\"Validating\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            outputs = model(\n",
    "                input_ids=batch[\"input_ids\"].to(device),\n",
    "                attention_mask=batch[\"attention_mask\"].to(device),\n",
    "                labels=batch[\"labels\"].to(device),\n",
    "            )\n",
    "\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()   # 0..3\n",
    "            labels = batch[\"labels\"].cpu().numpy()              # 0..3\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "            avg_so_far = total_loss / (pbar.n + 1)\n",
    "            pbar.set_postfix(avg_loss=f\"{avg_so_far:.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    qwk = cohen_kappa_score(all_labels + 1, all_preds + 1, weights=\"quadratic\")\n",
    "\n",
    "    return avg_loss, qwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T18:13:27.628571Z",
     "iopub.status.busy": "2026-01-24T18:13:27.628347Z",
     "iopub.status.idle": "2026-01-24T19:35:34.532192Z",
     "shell.execute_reply": "2026-01-24T19:35:34.531306Z",
     "shell.execute_reply.started": "2026-01-24T18:13:27.628552Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 0 =====\n",
      "Train batches: 322\n",
      " Val batches: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 0/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:29<00:00,  2.16it/s, avg=1.3548, loss=1.1107]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.84it/s, avg_loss=1.3244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.3548 | val_loss: 1.3244 | val_QWK: 0.0784\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold0.pth | best_QWK=0.0784\n",
      "\n",
      "--- Epoch 1/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.3065, loss=1.3584]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.82it/s, avg_loss=1.3091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.3065 | val_loss: 1.3091 | val_QWK: 0.2506\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold0.pth | best_QWK=0.2506\n",
      "\n",
      "--- Epoch 2/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.13it/s, avg=1.2053, loss=1.3368]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.83it/s, avg_loss=1.3276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.2053 | val_loss: 1.3276 | val_QWK: 0.2663\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold0.pth | best_QWK=0.2663\n",
      "\n",
      "--- Epoch 3/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.0063, loss=0.9027]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.82it/s, avg_loss=1.5226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.0063 | val_loss: 1.5226 | val_QWK: 0.2572\n",
      "\n",
      "--- Epoch 4/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=0.7202, loss=0.6113]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.83it/s, avg_loss=1.6085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.7202 | val_loss: 1.6085 | val_QWK: 0.2893\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold0.pth | best_QWK=0.2893\n",
      "\n",
      "--- Epoch 5/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=0.4398, loss=0.4131]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.82it/s, avg_loss=2.1877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.4398 | val_loss: 2.1877 | val_QWK: 0.2478\n",
      "\n",
      "FOLD 0 DONE | best_QWK=0.2893\n",
      "\n",
      "===== FOLD 1 =====\n",
      "Train batches: 322\n",
      " Val batches: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 0/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.3519, loss=1.3951]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.84it/s, avg_loss=1.2973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.3519 | val_loss: 1.2973 | val_QWK: 0.1381\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold1.pth | best_QWK=0.1381\n",
      "\n",
      "--- Epoch 1/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.2733, loss=1.2343]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.83it/s, avg_loss=1.2821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.2733 | val_loss: 1.2821 | val_QWK: 0.2009\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold1.pth | best_QWK=0.2009\n",
      "\n",
      "--- Epoch 2/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.1354, loss=1.1807]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.83it/s, avg_loss=1.3134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.1354 | val_loss: 1.3134 | val_QWK: 0.2804\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold1.pth | best_QWK=0.2804\n",
      "\n",
      "--- Epoch 3/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=0.8508, loss=1.2345]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.84it/s, avg_loss=1.4734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.8508 | val_loss: 1.4734 | val_QWK: 0.2917\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold1.pth | best_QWK=0.2917\n",
      "\n",
      "--- Epoch 4/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=0.5571, loss=0.6466]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.84it/s, avg_loss=1.9340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.5571 | val_loss: 1.9340 | val_QWK: 0.2707\n",
      "\n",
      "--- Epoch 5/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=0.3499, loss=0.4673]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.83it/s, avg_loss=2.1277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.3499 | val_loss: 2.1277 | val_QWK: 0.2492\n",
      "\n",
      "FOLD 1 DONE | best_QWK=0.2917\n",
      "\n",
      "===== FOLD 2 =====\n",
      "Train batches: 322\n",
      " Val batches: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 0/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.3484, loss=1.0790]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.82it/s, avg_loss=1.3221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.3484 | val_loss: 1.3221 | val_QWK: 0.1599\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold2.pth | best_QWK=0.1599\n",
      "\n",
      "--- Epoch 1/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.2481, loss=1.3283]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.82it/s, avg_loss=1.2843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.2481 | val_loss: 1.2843 | val_QWK: 0.2456\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold2.pth | best_QWK=0.2456\n",
      "\n",
      "--- Epoch 2/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.0809, loss=0.9560]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.82it/s, avg_loss=1.3101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.0809 | val_loss: 1.3101 | val_QWK: 0.2972\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold2.pth | best_QWK=0.2972\n",
      "\n",
      "--- Epoch 3/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=0.8084, loss=0.9655]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.83it/s, avg_loss=1.4732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.8084 | val_loss: 1.4732 | val_QWK: 0.2813\n",
      "\n",
      "--- Epoch 4/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=0.5361, loss=0.1739]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.82it/s, avg_loss=1.8062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.5361 | val_loss: 1.8062 | val_QWK: 0.2858\n",
      "\n",
      "--- Epoch 5/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=0.3165, loss=0.1095]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.81it/s, avg_loss=2.2364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.3165 | val_loss: 2.2364 | val_QWK: 0.2260\n",
      "\n",
      "FOLD 2 DONE | best_QWK=0.2972\n",
      "\n",
      "===== FOLD 3 =====\n",
      "Train batches: 322\n",
      " Val batches: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 0/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.3625, loss=1.3971]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.81it/s, avg_loss=1.3264]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.3625 | val_loss: 1.3264 | val_QWK: 0.1442\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold3.pth | best_QWK=0.1442\n",
      "\n",
      "--- Epoch 1/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.3011, loss=1.4656]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.83it/s, avg_loss=1.2976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.3011 | val_loss: 1.2976 | val_QWK: 0.1894\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold3.pth | best_QWK=0.1894\n",
      "\n",
      "--- Epoch 2/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.2107, loss=1.5260]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.82it/s, avg_loss=1.2840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.2107 | val_loss: 1.2840 | val_QWK: 0.2603\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold3.pth | best_QWK=0.2603\n",
      "\n",
      "--- Epoch 3/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.0292, loss=1.0734]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.81it/s, avg_loss=1.3210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.0292 | val_loss: 1.3210 | val_QWK: 0.2752\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold3.pth | best_QWK=0.2752\n",
      "\n",
      "--- Epoch 4/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=0.7461, loss=0.7172]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.82it/s, avg_loss=1.8774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.7461 | val_loss: 1.8774 | val_QWK: 0.2347\n",
      "\n",
      "--- Epoch 5/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=0.5045, loss=0.6461]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.81it/s, avg_loss=1.7750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.5045 | val_loss: 1.7750 | val_QWK: 0.2369\n",
      "\n",
      "FOLD 3 DONE | best_QWK=0.2752\n",
      "\n",
      "===== FOLD 4 =====\n",
      "Train batches: 322\n",
      " Val batches: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Epoch 0/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.3531, loss=1.4997]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.81it/s, avg_loss=1.3193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.3531 | val_loss: 1.3193 | val_QWK: 0.1560\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold4.pth | best_QWK=0.1560\n",
      "\n",
      "--- Epoch 1/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=1.2680, loss=0.9825]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.83it/s, avg_loss=1.3046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.2680 | val_loss: 1.3046 | val_QWK: 0.2267\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold4.pth | best_QWK=0.2267\n",
      "\n",
      "--- Epoch 2/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:32<00:00,  2.12it/s, avg=1.1406, loss=0.8980]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.81it/s, avg_loss=1.3214]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 1.1406 | val_loss: 1.3214 | val_QWK: 0.2569\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold4.pth | best_QWK=0.2569\n",
      "\n",
      "--- Epoch 3/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:32<00:00,  2.12it/s, avg=0.8938, loss=1.1866]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.82it/s, avg_loss=1.4228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.8938 | val_loss: 1.4228 | val_QWK: 0.2865\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold4.pth | best_QWK=0.2865\n",
      "\n",
      "--- Epoch 4/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:32<00:00,  2.12it/s, avg=0.6183, loss=0.1730]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.81it/s, avg_loss=1.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.6183 | val_loss: 1.7500 | val_QWK: 0.2933\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold4.pth | best_QWK=0.2933\n",
      "\n",
      "--- Epoch 5/6 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 322/322 [02:31<00:00,  2.12it/s, avg=0.3879, loss=0.3165]\n",
      "Validating: 100%|██████████| 81/81 [00:11<00:00,  6.82it/s, avg_loss=1.9869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.3879 | val_loss: 1.9869 | val_QWK: 0.3050\n",
      "✅ Saved best: /kaggle/working/artifacts/nlp_bert-base-cased_fold4.pth | best_QWK=0.3050\n",
      "\n",
      "FOLD 4 DONE | best_QWK=0.3050\n"
     ]
    }
   ],
   "source": [
    "WEIGHTS_DIR = Path(\"/kaggle/working/artifacts\")\n",
    "WEIGHTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    print(f\"\\n===== FOLD {fold} =====\")\n",
    "\n",
    "    train = master_df[master_df[\"fold\"] != fold].reset_index(drop=True)\n",
    "    val   = master_df[master_df[\"fold\"] == fold].reset_index(drop=True)\n",
    "\n",
    "    train_texts  = train[\"Description\"].values\n",
    "    train_labels = train[\"label\"].values\n",
    "\n",
    "    val_texts  = val[\"Description\"].values\n",
    "    val_labels = val[\"label\"].values\n",
    "\n",
    "    train_dataset = PetFinderDataset(train_texts, train_labels, max_length=max_length)\n",
    "    val_dataset   = PetFinderDataset(val_texts,   val_labels,   max_length=max_length)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "    )\n",
    "    print(\"Train batches:\", len(train_loader))\n",
    "    print(\" Val batches:\", len(val_loader))\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=4).to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "\n",
    "    best_qwk = -1e9\n",
    "    best_path = f\"{WEIGHTS_DIR}/nlp_{model_name}_fold{fold}.pth\"\n",
    "\n",
    "    # 6) epochs loop\n",
    "    for epoch in range(epochs): #, epochs + 1\n",
    "        print(f\"\\n--- Epoch {epoch}/{epochs} ---\")\n",
    "\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, device)  \n",
    "        val_loss, val_qwk = validate_one_epoch(model, val_loader, device)    \n",
    "\n",
    "        print(f\"train_loss: {train_loss:.4f} | val_loss: {val_loss:.4f} | val_QWK: {val_qwk:.4f}\")\n",
    "\n",
    "        # 7) save best weights\n",
    "        if val_qwk > best_qwk:\n",
    "            best_qwk = val_qwk\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f\"✅ Saved best: {best_path} | best_QWK={best_qwk:.4f}\")\n",
    "\n",
    "    print(f\"\\nFOLD {fold} DONE | best_QWK={best_qwk:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T19:41:32.992726Z",
     "iopub.status.busy": "2026-01-24T19:41:32.992116Z",
     "iopub.status.idle": "2026-01-24T19:41:32.996352Z",
     "shell.execute_reply": "2026-01-24T19:41:32.995737Z",
     "shell.execute_reply.started": "2026-01-24T19:41:32.992699Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ART = Path(\"/kaggle/working/artifacts\")\n",
    "ART.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T19:41:35.698942Z",
     "iopub.status.busy": "2026-01-24T19:41:35.698616Z",
     "iopub.status.idle": "2026-01-24T19:42:37.040347Z",
     "shell.execute_reply": "2026-01-24T19:42:37.039665Z",
     "shell.execute_reply.started": "2026-01-24T19:41:35.698915Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: /kaggle/working/artifacts/nlp_oof.csv\n"
     ]
    }
   ],
   "source": [
    "oof = np.zeros((len(master_df), 4), dtype=np.float32)\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    val = master_df[master_df.fold == fold].reset_index()\n",
    "    val_dataset = PetFinderDataset(val[\"Description\"].values, val[\"label\"].values, max_length=max_length)\n",
    "    val_loader  = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4).to(device)\n",
    "    model.load_state_dict(torch.load(ART / f\"nlp_{model_name}_fold{fold}.pth\", map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for b in val_loader:\n",
    "            out = model(input_ids=b[\"input_ids\"].to(device), attention_mask=b[\"attention_mask\"].to(device))\n",
    "            probs.append(torch.softmax(out.logits, 1).cpu().numpy())\n",
    "    oof[val[\"index\"].values] = np.vstack(probs)\n",
    "\n",
    "oof_df = pd.DataFrame({\"PetID\": master_df[\"PetID\"].values})\n",
    "for i in range(4): oof_df[f\"nlp_proba_{i+1}\"] = oof[:, i]\n",
    "oof_df[\"nlp_pred\"] = np.argmax(oof, 1) + 1\n",
    "oof_df.to_csv(ART / \"nlp_oof.csv\", index=False)\n",
    "print(\"saved:\", ART / \"nlp_oof.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T19:44:06.213681Z",
     "iopub.status.busy": "2026-01-24T19:44:06.213451Z",
     "iopub.status.idle": "2026-01-24T19:45:35.394727Z",
     "shell.execute_reply": "2026-01-24T19:45:35.393900Z",
     "shell.execute_reply.started": "2026-01-24T19:44:06.213661Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: /kaggle/working/artifacts/nlp_test.csv\n"
     ]
    }
   ],
   "source": [
    "test_dataset = PetFinderDataset(test_df[\"Description\"].fillna(\"\").values, labels=None, max_length=max_length)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "test_probs = np.zeros((len(test_df), 4), dtype=np.float32)\n",
    "\n",
    "for fold in range(n_folds):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4).to(device)\n",
    "    model.load_state_dict(torch.load(ART / f\"nlp_{model_name}_fold{fold}.pth\", map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    probs = []\n",
    "    with torch.no_grad():\n",
    "        for b in test_loader:\n",
    "            out = model(input_ids=b[\"input_ids\"].to(device), attention_mask=b[\"attention_mask\"].to(device))\n",
    "            probs.append(torch.softmax(out.logits, 1).cpu().numpy())\n",
    "    test_probs += np.vstack(probs)\n",
    "\n",
    "test_probs /= n_folds\n",
    "\n",
    "test_out = pd.DataFrame({\"PetID\": test_df[\"PetID\"].values})\n",
    "for i in range(4): test_out[f\"nlp_proba_{i+1}\"] = test_probs[:, i]\n",
    "test_out[\"nlp_pred\"] = np.argmax(test_probs, 1) + 1\n",
    "test_out.to_csv(ART / \"nlp_test.csv\", index=False)\n",
    "print(\"saved:\", ART / \"nlp_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 15390938,
     "sourceId": 128343,
     "sourceType": "competition"
    },
    {
     "datasetId": 9307592,
     "sourceId": 14571098,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
