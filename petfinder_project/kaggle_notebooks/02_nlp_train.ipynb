{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca3e5018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nolan\\Documents\\My dokuments\\GoIT\\Deep_learning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, random, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a430741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: C:\\Users\\Nolan\\Documents\\My dokuments\\GoIT\\Deep_learning\\petfinder_project\\kaggle_notebooks\n"
     ]
    }
   ],
   "source": [
    "print(\"CWD:\", Path().resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7cbc771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: C:\\Users\\Nolan\\Documents\\My dokuments\\GoIT\\Deep_learning\\petfinder_project\\kaggle_notebooks\n",
      "After : C:\\Users\\Nolan\\Documents\\My dokuments\\GoIT\\Deep_learning\\petfinder_project\n"
     ]
    }
   ],
   "source": [
    "print(\"Before:\", Path().resolve())\n",
    "os.chdir(\"..\")\n",
    "print(\"After :\", Path().resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7226e60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train exists: True\n",
      "test exists : True\n",
      "folds exists: True\n"
     ]
    }
   ],
   "source": [
    "COMP_PATH = Path(\"../petfinder_project/data/raw\")\n",
    "FOLDS_PATH = Path(\"../petfinder_project/data/artifacts/train_folds.csv\") \n",
    "\n",
    "train_csv = COMP_PATH / \"train.csv\"\n",
    "test_csv = COMP_PATH / \"test.csv\"\n",
    "\n",
    "print(\"train exists:\", train_csv.exists())\n",
    "print(\"test exists :\", test_csv.exists())\n",
    "print(\"folds exists:\", FOLDS_PATH.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f01473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (6431, 3)\n",
      "Test shape : (1891, 2)\n",
      "Folds shape: (6431, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_csv)\n",
    "test_df  = pd.read_csv(test_csv)\n",
    "folds_df = pd.read_csv(FOLDS_PATH)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape :\", test_df.shape)\n",
    "print(\"Folds shape:\", folds_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4de61de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6431 entries, 0 to 6430\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   PetID          6431 non-null   object\n",
      " 1   Description    6426 non-null   object\n",
      " 2   AdoptionSpeed  6431 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 150.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f86e8f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1891 entries, 0 to 1890\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   PetID        1891 non-null   object\n",
      " 1   Description  1890 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 29.7+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6dfcf850",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Description\"] = train_df[\"Description\"].fillna(\"\")\n",
    "test_df[\"Description\"] = test_df[\"Description\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86278eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdoptionSpeed\n",
      "1    1197\n",
      "2    1773\n",
      "3    1328\n",
      "4    2133\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df[\"AdoptionSpeed\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b97434b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset:\n",
      "       PetID                                        Description  AdoptionSpeed\n",
      "0  d3b4f29f8  Mayleen and Flo are two lovely adorable sister...              2\n",
      "1  e9dc82251  A total of 5 beautiful Tabbys available for ad...              2\n",
      "2  8111f6d4a  Two-and-a-half month old girl. Very manja and ...              2\n",
      "3  693a90fda  Neil is a healthy and active ~2-month-old fema...              2\n",
      "4  9d08c85ef  Gray kitten available for adoption in sungai p...              2 \n",
      "\n",
      "test dataset:\n",
      "       PetID                                        Description\n",
      "0  6697a7f62  This cute little puppy is looking for a loving...\n",
      "1  23b64fe21  These 3 puppies was rescued from a mechanic sh...\n",
      "2  41e824cbe  Ara needs a forever home! Believe me, he's a r...\n",
      "3  6c3d7237b  i rescue this homeless dog 2 years ago but my ...\n",
      "4  97b0b5d92  We found him at a shopping mall at a very clea... \n",
      "\n",
      "folds dataset:\n",
      "       PetID  AdoptionSpeed  fold\n",
      "0  d3b4f29f8              2     3\n",
      "1  e9dc82251              2     3\n",
      "2  8111f6d4a              2     2\n",
      "3  693a90fda              2     4\n",
      "4  9d08c85ef              2     3\n"
     ]
    }
   ],
   "source": [
    "print(\"train dataset:\")\n",
    "print(train_df.head(), \"\\n\")\n",
    "print(\"test dataset:\")\n",
    "print(test_df.head(), \"\\n\")\n",
    "print(\"folds dataset:\")\n",
    "print(folds_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e291451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc4e714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 7b321ad5-ad70-4741-8cee-d0e726c935fb)')' thrown while requesting HEAD https://huggingface.co/distilbert-base-cased/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-cased\"\n",
    "num_classes = 4\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_classes).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6e9efb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Mayleen and Flo are two lovely adorable sisters. They are very friendly and affectionate, but wary of strangers and make good watchdogs. Mayleen has golden hues on her face, making her a husky look - alike. Flo has a darker face with brown feet, and is the more outgoing and dominat of the two. Looking for good homes. Adopters must vaccinate and spay them. [SEP]'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = train_df.loc[0, \"Description\"]  \n",
    "inputs = tokenizer(text)\n",
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "df0f3fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Mayleen and Flo are two lovely adorable sisters. They are very friendly and affectionate, but wary of strangers and make good watchdogs. Mayleen has golden hues on her face, making her a husky look - alike. Flo has a darker face with brown feet, and is the more outgoing and dominat of the two. Looking for good homes. Adopters must vaccinate and spay them. [SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer( \n",
    "    text, \n",
    "    max_length=200, \n",
    "    truncation=True,\n",
    "    return_overflowing_tokens=True, \n",
    ") \n",
    "  \n",
    "for ids in inputs[\"input_ids\"]: \n",
    "    print(tokenizer.decode(ids)); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "99aabf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeysView({'input_ids': [[101, 1318, 21180, 1105, 143, 2858, 1132, 1160, 9020, 27627, 5919, 119, 1220, 1132, 1304, 4931, 1105, 12721, 2193, 117, 1133, 16970, 1104, 15712, 1105, 1294, 1363, 2824, 14082, 1116, 119, 1318, 21180, 1144, 5404, 177, 10589, 1113, 1123, 1339, 117, 1543, 1123, 170, 24418, 1440, 118, 11609, 119, 143, 2858, 1144, 170, 9934, 1339, 1114, 3058, 1623, 117, 1105, 1110, 1103, 1167, 25194, 1105, 1202, 14503, 1204, 1104, 1103, 1160, 119, 8540, 1111, 1363, 4481, 119, 24930, 4184, 5759, 1538, 191, 7409, 16430, 2193, 1105, 22620, 1183, 1172, 119, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'offset_mapping': [[(0, 0), (0, 3), (3, 7), (8, 11), (12, 13), (13, 15), (16, 19), (20, 23), (24, 30), (31, 39), (40, 47), (47, 48), (49, 53), (54, 57), (58, 62), (63, 71), (72, 75), (76, 85), (85, 88), (88, 89), (90, 93), (94, 98), (99, 101), (102, 111), (112, 115), (116, 120), (121, 125), (126, 131), (131, 134), (134, 135), (135, 136), (137, 140), (140, 144), (145, 148), (149, 155), (156, 157), (157, 160), (161, 163), (164, 167), (168, 172), (172, 173), (174, 180), (181, 184), (185, 186), (187, 192), (193, 197), (197, 198), (198, 203), (203, 204), (205, 206), (206, 208), (209, 212), (213, 214), (215, 221), (222, 226), (227, 231), (232, 237), (238, 242), (242, 243), (244, 247), (248, 250), (251, 254), (255, 259), (260, 268), (269, 272), (273, 275), (275, 279), (279, 280), (281, 283), (284, 287), (288, 291), (291, 292), (293, 300), (301, 304), (305, 309), (310, 315), (315, 316), (317, 319), (319, 321), (321, 325), (326, 330), (331, 332), (332, 334), (334, 337), (337, 340), (341, 344), (345, 348), (348, 349), (350, 354), (354, 355), (0, 0)]], 'overflow_to_sample_mapping': [0]})\n",
      "num chunks: 1\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer( \n",
    "    text, \n",
    "    max_length=200, \n",
    "    truncation=True, \n",
    "    return_overflowing_tokens=True, \n",
    "    return_offsets_mapping=True, \n",
    " ) \n",
    "inputs.keys()\n",
    "print(inputs.keys())\n",
    "print(\"num chunks:\", len(inputs[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ef068e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1173 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 6431\n",
      "min  : 2\n",
      "p50  : 66\n",
      "p90  : 199\n",
      "p95  : 287\n",
      "p99  : 557\n",
      "max  : 1487\n"
     ]
    }
   ],
   "source": [
    "lengths = train_df[\"Description\"].fillna(\"\").astype(str).apply(\n",
    "    lambda x: len(tokenizer(x, add_special_tokens=True, truncation=False)[\"input_ids\"])\n",
    ")\n",
    "\n",
    "print(\"count:\", lengths.shape[0])\n",
    "print(\"min  :\", lengths.min())\n",
    "print(\"p50  :\", int(lengths.quantile(0.50)))\n",
    "print(\"p90  :\", int(lengths.quantile(0.90)))\n",
    "print(\"p95  :\", int(lengths.quantile(0.95)))\n",
    "print(\"p99  :\", int(lengths.quantile(0.99)))\n",
    "print(\"max  :\", lengths.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94182514",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetFinderDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, max_length=287):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "   \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        inputs = tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "       \n",
    "        item = {key: val.squeeze(0) for key, val in inputs.items()}\n",
    "       \n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "       \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "328261e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Description\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8442750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_length = 288\n",
    "n_folds = 5\n",
    "num_workers = 0 \n",
    "epochs = 3\n",
    "lr = 2e-5     \n",
    "pin_memory = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "09eb4307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (6431, 4)\n",
      "missing fold: 0\n"
     ]
    }
   ],
   "source": [
    "master_df = train_df.merge(\n",
    "    folds_df[[\"PetID\", \"fold\"]],\n",
    "    on=\"PetID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "print(\"shape:\", master_df.shape)\n",
    "print(\"missing fold:\", master_df[\"fold\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "336142ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4\n",
      "0 3\n"
     ]
    }
   ],
   "source": [
    "master_df[\"label\"] = master_df[\"AdoptionSpeed\"] - 1  # Convert to 0-3\n",
    "print(master_df[\"AdoptionSpeed\"].min(), master_df[\"AdoptionSpeed\"].max())\n",
    "print(master_df[\"label\"].min(), master_df[\"label\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14a5bb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "№ Fold: 0\n",
      "Train batches: 322\n",
      " Val batches: 81 \n",
      "\n",
      "№ Fold: 1\n",
      "Train batches: 322\n",
      " Val batches: 81 \n",
      "\n",
      "№ Fold: 2\n",
      "Train batches: 322\n",
      " Val batches: 81 \n",
      "\n",
      "№ Fold: 3\n",
      "Train batches: 322\n",
      " Val batches: 81 \n",
      "\n",
      "№ Fold: 4\n",
      "Train batches: 322\n",
      " Val batches: 81 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in range(n_folds):\n",
    "    print(\"№ Fold:\", fold)\n",
    "\n",
    "    train = master_df[master_df[\"fold\"] != fold]\n",
    "    val = master_df[master_df[\"fold\"] == fold]\n",
    "\n",
    "    train_texts = train[\"Description\"].values\n",
    "    train_labels = train[\"label\"].values\n",
    "\n",
    "    val_texts = val[\"Description\"].values\n",
    "    val_labels = val[\"label\"].values\n",
    "\n",
    "    train_dataset = PetFinderDataset(\n",
    "        texts=train_texts,\n",
    "        labels=train_labels,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    val_dataset = PetFinderDataset(\n",
    "        texts=val_texts,\n",
    "        labels=val_labels,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "\n",
    "    print(\"Train batches:\", len(train_loader))\n",
    "    print(\" Val batches:\", len(val_loader), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "11076df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([16, 288]) torch.int64\n",
      "attention_mask torch.Size([16, 288]) torch.int64\n",
      "labels torch.Size([16]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape, v.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3371b1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels min/max: 0 3\n",
      "unique (first 50): tensor([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"labels min/max:\", batch[\"labels\"].min().item(), batch[\"labels\"].max().item())\n",
    "print(\"unique (first 50):\", torch.unique(batch[\"labels\"])[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ec32105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.4373)\n",
      "logits shape: torch.Size([16, 4])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=batch[\"input_ids\"].to(device),\n",
    "        attention_mask=batch[\"attention_mask\"].to(device),\n",
    "        labels=batch[\"labels\"].to(device),\n",
    "    )\n",
    "\n",
    "print(\"loss:\", outputs.loss)\n",
    "print(\"logits shape:\", outputs.logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ba9882b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step loss: 1.456268548965454\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "outputs = model(\n",
    "    input_ids=batch[\"input_ids\"].to(device),\n",
    "    attention_mask=batch[\"attention_mask\"].to(device),\n",
    "    labels=batch[\"labels\"].to(device),\n",
    ")\n",
    "loss = outputs.loss\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(\"train step loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9058c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_qwk(model, val_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
