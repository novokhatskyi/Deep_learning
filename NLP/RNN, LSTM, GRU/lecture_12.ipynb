{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3642a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n",
      "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
      "Collecting de-core-news-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en\n",
    "!python3 -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45876da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 MB\u001b[0m \u001b[31m259.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m262.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m295.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m403.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m305.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m254.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m298.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m203.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m157.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m208.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m286.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m263.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m369.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m217.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!python -m pip uninstall -y torchtext torchdata torchaudio torchvision torch -q\n",
    "!python -m pip install -U --no-cache-dir --index-url https://download.pytorch.org/whl/cu121 \\\n",
    "  torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 -q\n",
    "!python -m pip install -U --no-cache-dir torchtext==0.18.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7945942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
      "torch: 2.3.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch, sys, platform\n",
    "print(\"python:\", sys.version)\n",
    "print(\"platform:\", platform.platform())\n",
    "print(\"torch:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f2fb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121 0.18.0+cpu 0.18.0+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch, torchtext, torchvision\n",
    "print(torch.__version__, torchtext.__version__, torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "859419d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.6\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86555326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/usr/local/lib/python3.12/dist-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import tqdm\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "import sys\n",
    "\n",
    "import en_core_web_sm\n",
    "import de_core_news_sm\n",
    "\n",
    "import datasets\n",
    "import torchtext\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "349b9f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Running in Colab\n"
     ]
    }
   ],
   "source": [
    "# 1. Environment diagnostics\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"➡️ Running in Colab\")\n",
    "else:\n",
    "    print(\"➡️ Running in local Python / VS Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f2c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6163919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e516fc46125344958742332193d22117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0a82b91fc64470822a0b8028f51f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309e4d66859c4ad58701de36815fe33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5941a77b7aa8437f8654b5d937fadb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.jsonl: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f308f9d3bd2a4709aa00fe216a185ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/29000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab19e1ade214c3d9a19c1ff72ea97a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8cd0edbccb4ad1bc316337c86bf105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 29000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1014\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"bentrevett/multi30k\")\n",
    "\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e7ce48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, valid_data, test_data = dataset[\"train\"], dataset[\"validation\"], dataset[\"test\"] \n",
    "train_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da06e64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7c26593f-f695-440e-b7ee-1ca5f24de536\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>de</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two young, White males are outside near many bushes.</td>\n",
       "      <td>Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Several men in hard hats are operating a giant pulley system.</td>\n",
       "      <td>Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A little girl climbing into a wooden playhouse.</td>\n",
       "      <td>Ein kleines Mädchen klettert in ein Spielhaus aus Holz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man in a blue shirt is standing on a ladder cleaning a window.</td>\n",
       "      <td>Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two men are at the stove preparing food.</td>\n",
       "      <td>Zwei Männer stehen am Herd und bereiten Essen zu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c26593f-f695-440e-b7ee-1ca5f24de536')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7c26593f-f695-440e-b7ee-1ca5f24de536 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7c26593f-f695-440e-b7ee-1ca5f24de536');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                                 en  \\\n",
       "0              Two young, White males are outside near many bushes.   \n",
       "1     Several men in hard hats are operating a giant pulley system.   \n",
       "2                   A little girl climbing into a wooden playhouse.   \n",
       "3  A man in a blue shirt is standing on a ladder cleaning a window.   \n",
       "4                          Two men are at the stove preparing food.   \n",
       "\n",
       "                                                                            de  \n",
       "0            Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.  \n",
       "1              Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.  \n",
       "2                      Ein kleines Mädchen klettert in ein Spielhaus aus Holz.  \n",
       "3  Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.  \n",
       "4                            Zwei Männer stehen am Herd und bereiten Essen zu.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None):\n",
    "    example_df = pd.DataFrame(train_data[:5])\n",
    "    display(example_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e227160",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = en_core_web_sm.load()\n",
    "de_nlp = de_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "845c7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(    \n",
    "    example,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    max_length,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token\n",
    "):\n",
    "    '''\n",
    "    Tokenizes a textual English-German input pair.    \n",
    "    Args:\n",
    "        example: (dict) a dictionary with one phrase in English and German; keys 'en', 'de'\n",
    "        en_nlp: (spacy.lang) a spacy language model for English\n",
    "        de_nlp: (spacy.lang) a spacy language model for German\n",
    "        max_length: (int) max input sentence length, symbols\n",
    "        lower: (bool) if to lowercase input\n",
    "        sos_token: (str) a start_of_sequence token\n",
    "        eos_token: (str) an end_of_sequence token\n",
    "    \n",
    "    Return:    \n",
    "        (dict) pre-processed and tokenized input sequence  \n",
    "    '''\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23b8355d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9796f28e13114e90ab44996fdd814fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adc9b0811fa4a2fa84c85682adebcbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229cf2b28678463c898eecc05ccdf75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiße',\n",
       "  'männer',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nähe',\n",
       "  'vieler',\n",
       "  'büsche',\n",
       "  '.',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 1_000\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp, \n",
    "    \"de_nlp\": de_nlp, \n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "\n",
    "train_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0180a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Linux-6.6.105+-x86_64-with-glibc2.35\n",
      "Python: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "torch: 2.3.0+cu121\n",
      "torch CUDA: 12.1\n",
      "CUDA available: True\n",
      "GPU: Tesla T4\n",
      "torchtext: 0.18.0+cpu\n",
      "torchvision: 0.18.0+cu121\n",
      "torchaudio: 2.3.0+cu121\n",
      "datasets: 4.0.0\n",
      "transformers: 4.57.3\n",
      "tokenizers: 0.22.1\n",
      "spacy: 3.8.11\n",
      "triton: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "import sys, platform\n",
    "import torch, torchtext\n",
    "\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torch CUDA:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "print(\"torchtext:\", torchtext.__version__)\n",
    "\n",
    "# інші важливі пакети (якщо встановлені)\n",
    "pkgs = [\n",
    "    \"torchvision\",\"torchaudio\",\"torchdata\",\n",
    "    \"datasets\",\"transformers\",\"tokenizers\",\"spacy\",\n",
    "    \"pytorch_lightning\",\"torchmetrics\",\n",
    "    \"xformers\",\"flash_attn\",\"bitsandbytes\",\"triton\"\n",
    "]\n",
    "import importlib\n",
    "for p in pkgs:\n",
    "    try:\n",
    "        m = importlib.import_module(p)\n",
    "        v = getattr(m, \"__version__\", \"no __version__\")\n",
    "        print(f\"{p}: {v}\")\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82342dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a vocab\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "min_freq = 2 # minimum frequency of occurrence in the text\n",
    "unk_token = \"<unk>\" # unknown token\n",
    "pad_token = \"<pad>\" # padding token\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "en_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,  \n",
    ")\n",
    "\n",
    "de_vocab = torchtext.vocab.build_vocab_from_iterator(\n",
    "    train_data[\"de_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29df5429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "7\n",
      "men\n"
     ]
    }
   ],
   "source": [
    "assert en_vocab[unk_token] == de_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == de_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]\n",
    "\n",
    "print(unk_index)\n",
    "print(pad_index)\n",
    "\n",
    "print(en_vocab['the'])\n",
    "print(en_vocab.get_itos()[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87c32698",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(en_vocab[unk_token])\n",
    "de_vocab.set_default_index(de_vocab[unk_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40a46d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_vocab, de_vocab):\n",
    "    '''\n",
    "    Creates a mapping from string tokens to the vocabulary indexes.\n",
    "    '''\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    de_ids = de_vocab.lookup_indices(example[\"de_tokens\"])\n",
    "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c4e99d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89aea5aca20143cd9af4e792fec3679f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856fad70f5fe4ff7bf973fc133469249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e6678b9ae343bc915deb7a0b02e1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'en': 'Two young, White males are outside near many bushes.',\n",
       " 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'two',\n",
       "  'young',\n",
       "  ',',\n",
       "  'white',\n",
       "  'males',\n",
       "  'are',\n",
       "  'outside',\n",
       "  'near',\n",
       "  'many',\n",
       "  'bushes',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'de_tokens': ['<sos>',\n",
       "  'zwei',\n",
       "  'junge',\n",
       "  'weiße',\n",
       "  'männer',\n",
       "  'sind',\n",
       "  'im',\n",
       "  'freien',\n",
       "  'in',\n",
       "  'der',\n",
       "  'nähe',\n",
       "  'vieler',\n",
       "  'büsche',\n",
       "  '.',\n",
       "  '<eos>'],\n",
       " 'en_ids': [2, 16, 24, 15, 25, 778, 17, 57, 80, 202, 1312, 5, 3],\n",
       " 'de_ids': [2, 18, 26, 253, 30, 84, 20, 88, 7, 15, 110, 7647, 3171, 4, 3]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_kwargs = {\n",
    "    \"en_vocab\": en_vocab, \n",
    "    \"de_vocab\": de_vocab\n",
    "}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "\n",
    "train_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10727806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['en', 'de', 'en_tokens', 'de_tokens', 'en_ids', 'de_ids'],\n",
       "    num_rows: 29000\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"de_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type, \n",
    "    columns=format_columns, \n",
    "    output_all_columns=True\n",
    ")\n",
    "\n",
    "valid_data = valid_data.with_format(\n",
    "    type=data_type, \n",
    "    columns=format_columns, \n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type, \n",
    "    columns=format_columns, \n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2569206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    '''\n",
    "    Adding padding as a part of a collate_fn.\n",
    "    '''\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_de_ids = [example[\"de_ids\"] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"de_ids\": batch_de_ids,\n",
    "        }\n",
    "        return batch\n",
    "    \n",
    "    return collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d53cf447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    \n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    \n",
    "    return data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9e2f2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
       "         [   4,    9,    4,  ...,    4,    9,    4],\n",
       "         [ 719, 1041,   59,  ...,    9,   22,    9],\n",
       "         ...,\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1]]),\n",
       " 'de_ids': tensor([[   2,    2,    2,  ...,    2,    2,    2],\n",
       "         [   8,    5,    8,  ...,    5,    5,    5],\n",
       "         [1058,   13,  168,  ...,   13,   13,   13],\n",
       "         ...,\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1],\n",
       "         [   1,    1,    1,  ...,    1,    1,    1]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)\n",
    "\n",
    "next(iter(train_data_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f3c53b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c719ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU(embedding_dim, encoder_hidden_dim, bidirectional = True)\n",
    "        self.fc = nn.Linear(encoder_hidden_dim * 2, decoder_hidden_dim)\n",
    "        \n",
    "    def forward(self, src): # (src_length, batch size)\n",
    "        embedded = self.embedding(src) # (src_length, batch_size, embedding_dim)\n",
    "\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "        # outputs (src_length, batch_size, hidden dim * n_directions)\n",
    "        # hidden (n_layers * n_directions, batch_size, hidden dim)\n",
    "        \n",
    "        # hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        \n",
    "        # outputs are always from the last layer\n",
    "        # hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        # hidden [-1, :, : ] is the last of the backwards RNN\n",
    "       \n",
    "        # initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        # encoder RNNs fed through a linear layer\n",
    "        \n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)))\n",
    "        \n",
    "        # outputs (src_length, batch_size, encoder_hidden_dim * 2)\n",
    "        # hidden (batch_size, decoder_hidden_dim)\n",
    "        \n",
    "        return outputs, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d23b928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn_fc = nn.Linear(\n",
    "            (encoder_hidden_dim * 2) + decoder_hidden_dim, \n",
    "            decoder_hidden_dim\n",
    "        )\n",
    "        self.v_fc = nn.Linear(decoder_hidden_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):        \n",
    "        # hidden (batch_size, decoder_hidden_dim)\n",
    "        # encoder_outputs (src_length, batch_size, encoder_hidden dim * 2)\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_length = encoder_outputs.shape[0]\n",
    "        \n",
    "        # repeat decoder hidden state src_length times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_length, 1) # (batch_size, src_length, decoder_hidden_dim)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2) # (batch_size, src_length, encoder_hidden_dim * 2)\n",
    "        \n",
    "        energy = torch.tanh(self.attn_fc(torch.cat((hidden, encoder_outputs), dim=2))) \n",
    "        # (batch_size, src_length, decoder_hidden_dim)\n",
    "\n",
    "        attention = self.v_fc(energy).squeeze(2) # batch_size, src_length\n",
    "\n",
    "        return torch.softmax(attention, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51e0c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim,\n",
    "        embedding_dim,\n",
    "        encoder_hidden_dim,\n",
    "        decoder_hidden_dim,\n",
    "        attention,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.GRU((encoder_hidden_dim * 2) + embedding_dim, decoder_hidden_dim) \n",
    "        self.fc_out = nn.Linear(\n",
    "            (encoder_hidden_dim * 2) + decoder_hidden_dim + embedding_dim, \n",
    "            output_dim\n",
    "        )\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input = (batch_size)\n",
    "        # hidden = batch_size, decoder hidden dim]\n",
    "        # encoder_outputs = [src length, batch size, encoder hidden dim * 2]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.embedding(input)\n",
    "        #embedded = [1, batch size, embedding dim]\n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        # a = [batch size, src length]\n",
    "        a = a.unsqueeze(1)\n",
    "        # a = [batch size, 1, src length]\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        # encoder_outputs = [batch size, src length, encoder hidden dim * 2]\n",
    "        weighted = torch.bmm(a, encoder_outputs) # batch matrix-matrix product\n",
    "        # weighted = [batch size, 1, encoder hidden dim * 2]\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        # weighted = [1, batch size, encoder hidden dim * 2]\n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        # rnn_input = [1, batch size, (encoder hidden dim * 2) + embedding dim]\n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        # output = [seq length, batch size, decoder hid dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, decoder hid dim]\n",
    "        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, decoder hidden dim]\n",
    "        # hidden = [1, batch size, decoder hidden dim]\n",
    "        # this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "        #prediction = [batch size, output dim]\n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61379259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "        batch_size = src.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        # hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        # outputs = [src length, batch size, encoder hidden dim * 2]\n",
    "        # hidden = [batch size, decoder hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            # receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [n layers, batch size, decoder hidden dim]\n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f8ead17",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(de_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "encoder_hidden_dim = 512\n",
    "decoder_hidden_dim = 512\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_dir = './saved_models'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b2ebf58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn_fc): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v_fc): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = Attention(encoder_hidden_dim, decoder_hidden_dim)\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    encoder_hidden_dim,\n",
    "    decoder_hidden_dim\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    encoder_hidden_dim,\n",
    "    decoder_hidden_dim,\n",
    "    attention,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b92e4a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(7853, 256)\n",
       "    (rnn): GRU(256, 512, bidirectional=True)\n",
       "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn_fc): Linear(in_features=1536, out_features=512, bias=True)\n",
       "      (v_fc): Linear(in_features=512, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(5893, 256)\n",
       "    (rnn): GRU(1280, 512)\n",
       "    (fc_out): Linear(in_features=1792, out_features=5893, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "    Initiates model weights from the normal distribution.\n",
    "    Sets bias to 0.\n",
    "    \"\"\"\n",
    "    for name, param in m.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "457fd331",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f0d8575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in tqdm.tqdm(enumerate(data_loader)):\n",
    "        src = batch[\"de_ids\"].to(device)\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"de_ids\"].to(device)\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82e233d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [01:27,  2.61it/s]0:00<?, ?it/s]\n",
      " 10%|█         | 1/10 [01:28<13:16, 88.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\tTrain Loss:   5.006\n",
      "\\tValid Loss:   4.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [01:30,  2.51it/s]\n",
      " 20%|██        | 2/10 [03:00<12:04, 90.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\tTrain Loss:   4.058\n",
      "\\tValid Loss:   4.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [01:30,  2.52it/s]\n",
      " 30%|███       | 3/10 [04:32<10:37, 91.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\tTrain Loss:   3.346\n",
      "\\tValid Loss:   3.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [01:30,  2.51it/s]\n",
      " 40%|████      | 4/10 [06:04<09:08, 91.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\tTrain Loss:   2.736\n",
      "\\tValid Loss:   3.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [01:30,  2.51it/s]\n",
      " 50%|█████     | 5/10 [07:36<07:38, 91.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\tTrain Loss:   2.323\n",
      "\\tValid Loss:   3.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [01:30,  2.52it/s]\n",
      " 60%|██████    | 6/10 [09:07<06:06, 91.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\tTrain Loss:   2.018\n",
      "\\tValid Loss:   3.254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [01:31,  2.48it/s]\n",
      " 70%|███████   | 7/10 [10:40<04:36, 92.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\tTrain Loss:   1.722\n",
      "\\tValid Loss:   3.337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [01:31,  2.49it/s]\n",
      " 80%|████████  | 8/10 [12:13<03:04, 92.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\tTrain Loss:   1.518\n",
      "\\tValid Loss:   3.372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [01:30,  2.50it/s]\n",
      " 90%|█████████ | 9/10 [13:45<01:32, 92.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\tTrain Loss:   1.340\n",
      "\\tValid Loss:   3.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [01:30,  2.50it/s]\n",
      "100%|██████████| 10/10 [15:17<00:00, 91.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\tTrain Loss:   1.193\n",
      "\\tValid Loss:   3.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0 # gradient clipping\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "model_dir = \"./saved_models\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "        \n",
    "    train_loss=train_fn(\n",
    "        model, \n",
    "        train_data_loader, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        clip, \n",
    "        teacher_forcing_ratio, \n",
    "        device,\n",
    "    )\n",
    "    \n",
    "    valid_loss = evaluate_fn(\n",
    "        model, \n",
    "        valid_data_loader, \n",
    "        criterion, \n",
    "        device,\n",
    "    )\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, 'en_de.pt'))\n",
    "    \n",
    "    print(f\"\\\\tTrain Loss: {train_loss:7.3f}\")\n",
    "    print(f\"\\\\tValid Loss: {valid_loss:7.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b73fe159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 3.308 | Test PPL:  27.332 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(model_dir, 'en_de.pt'), map_location=device))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79c497ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(\n",
    "    sentence, \n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(sentence, str):\n",
    "            de_tokens = [token.text for token in de_nlp.tokenizer(sentence)]\n",
    "        else:\n",
    "            de_tokens = [token for token in sentence]\n",
    "        if lower:\n",
    "            de_tokens = [token.lower() for token in de_tokens]\n",
    "        de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "        ids = de_vocab.lookup_indices(de_tokens)\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        \n",
    "        encoder_outputs, hidden = model.encoder(tensor)\n",
    "        \n",
    "        inputs = en_vocab.lookup_indices([sos_token])\n",
    "        \n",
    "        attentions = torch.zeros(max_output_length, 1, len(ids))\n",
    "        \n",
    "        for i in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden, attention = model.decoder(inputs_tensor, hidden, encoder_outputs)\n",
    "            attentions[i] = attention\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "        en_tokens = en_vocab.lookup_tokens(inputs)\n",
    "    return en_tokens, de_tokens, attentions[:len(en_tokens)-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "59f85769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(sentence, translation, attention):\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    attention = attention.squeeze(1).numpy()\n",
    "    cax = ax.matshow(attention, cmap=\"bone\")\n",
    "    ax.set_xticks(ticks=np.arange(len(sentence)), labels=sentence, rotation=90, size=15)\n",
    "    translation = translation[1:]\n",
    "    ax.set_yticks(ticks=np.arange(len(translation)), labels=translation, size=15)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3db5543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.',\n",
       " 'A man in an orange hat starring at something.')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = test_data[0][\"de\"]\n",
    "expected_translation = test_data[0][\"en\"]\n",
    "\n",
    "sentence, expected_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d072234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', 'a', 'man', 'in', 'an', 'orange', 'hat', 'is', 'something', 'something', '.', '<eos>']\n",
      "['<sos>', 'ein', 'mann', 'mit', 'einem', 'orangefarbenen', 'hut', ',', 'der', 'etwas', 'anstarrt', '.', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translation, sentence_tokens, attention = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")\n",
    "\n",
    "print(translation)\n",
    "print(sentence_tokens)\n",
    "plot_attention(sentence_tokens, translation, attention)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
